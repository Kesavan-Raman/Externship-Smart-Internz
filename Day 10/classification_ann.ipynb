{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fish.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length1</th>\n",
       "      <th>Length2</th>\n",
       "      <th>Length3</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bream</td>\n",
       "      <td>242.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>25.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bream</td>\n",
       "      <td>290.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bream</td>\n",
       "      <td>340.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bream</td>\n",
       "      <td>363.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bream</td>\n",
       "      <td>430.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Species  Weight  Length1  Length2  Length3   Height   Width\n",
       "0   Bream   242.0     23.2     25.4     30.0  11.5200  4.0200\n",
       "1   Bream   290.0     24.0     26.3     31.2  12.4800  4.3056\n",
       "2   Bream   340.0     23.9     26.5     31.1  12.3778  4.6961\n",
       "3   Bream   363.0     26.3     29.0     33.5  12.7300  4.4555\n",
       "4   Bream   430.0     26.5     29.0     34.0  12.4440  5.1340"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bream', 'Roach', 'Whitefish', 'Parkki', 'Perch', 'Pike', 'Smelt'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Species\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Species    False\n",
       "Weight     False\n",
       "Length1    False\n",
       "Length2    False\n",
       "Length3    False\n",
       "Height     False\n",
       "Width      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, 1:7].values\n",
    "y = df.iloc[:, 0:1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.42000e+02, 2.32000e+01, 2.54000e+01, 3.00000e+01, 1.15200e+01,\n",
       "        4.02000e+00],\n",
       "       [2.90000e+02, 2.40000e+01, 2.63000e+01, 3.12000e+01, 1.24800e+01,\n",
       "        4.30560e+00],\n",
       "       [3.40000e+02, 2.39000e+01, 2.65000e+01, 3.11000e+01, 1.23778e+01,\n",
       "        4.69610e+00],\n",
       "       [3.63000e+02, 2.63000e+01, 2.90000e+01, 3.35000e+01, 1.27300e+01,\n",
       "        4.45550e+00],\n",
       "       [4.30000e+02, 2.65000e+01, 2.90000e+01, 3.40000e+01, 1.24440e+01,\n",
       "        5.13400e+00],\n",
       "       [4.50000e+02, 2.68000e+01, 2.97000e+01, 3.47000e+01, 1.36024e+01,\n",
       "        4.92740e+00],\n",
       "       [5.00000e+02, 2.68000e+01, 2.97000e+01, 3.45000e+01, 1.41795e+01,\n",
       "        5.27850e+00],\n",
       "       [3.90000e+02, 2.76000e+01, 3.00000e+01, 3.50000e+01, 1.26700e+01,\n",
       "        4.69000e+00],\n",
       "       [4.50000e+02, 2.76000e+01, 3.00000e+01, 3.51000e+01, 1.40049e+01,\n",
       "        4.84380e+00],\n",
       "       [5.00000e+02, 2.85000e+01, 3.07000e+01, 3.62000e+01, 1.42266e+01,\n",
       "        4.95940e+00],\n",
       "       [4.75000e+02, 2.84000e+01, 3.10000e+01, 3.62000e+01, 1.42628e+01,\n",
       "        5.10420e+00],\n",
       "       [5.00000e+02, 2.87000e+01, 3.10000e+01, 3.62000e+01, 1.43714e+01,\n",
       "        4.81460e+00],\n",
       "       [5.00000e+02, 2.91000e+01, 3.15000e+01, 3.64000e+01, 1.37592e+01,\n",
       "        4.36800e+00],\n",
       "       [3.40000e+02, 2.95000e+01, 3.20000e+01, 3.73000e+01, 1.39129e+01,\n",
       "        5.07280e+00],\n",
       "       [6.00000e+02, 2.94000e+01, 3.20000e+01, 3.72000e+01, 1.49544e+01,\n",
       "        5.17080e+00],\n",
       "       [6.00000e+02, 2.94000e+01, 3.20000e+01, 3.72000e+01, 1.54380e+01,\n",
       "        5.58000e+00],\n",
       "       [7.00000e+02, 3.04000e+01, 3.30000e+01, 3.83000e+01, 1.48604e+01,\n",
       "        5.28540e+00],\n",
       "       [7.00000e+02, 3.04000e+01, 3.30000e+01, 3.85000e+01, 1.49380e+01,\n",
       "        5.19750e+00],\n",
       "       [6.10000e+02, 3.09000e+01, 3.35000e+01, 3.86000e+01, 1.56330e+01,\n",
       "        5.13380e+00],\n",
       "       [6.50000e+02, 3.10000e+01, 3.35000e+01, 3.87000e+01, 1.44738e+01,\n",
       "        5.72760e+00],\n",
       "       [5.75000e+02, 3.13000e+01, 3.40000e+01, 3.95000e+01, 1.51285e+01,\n",
       "        5.56950e+00],\n",
       "       [6.85000e+02, 3.14000e+01, 3.40000e+01, 3.92000e+01, 1.59936e+01,\n",
       "        5.37040e+00],\n",
       "       [6.20000e+02, 3.15000e+01, 3.45000e+01, 3.97000e+01, 1.55227e+01,\n",
       "        5.28010e+00],\n",
       "       [6.80000e+02, 3.18000e+01, 3.50000e+01, 4.06000e+01, 1.54686e+01,\n",
       "        6.13060e+00],\n",
       "       [7.00000e+02, 3.19000e+01, 3.50000e+01, 4.05000e+01, 1.62405e+01,\n",
       "        5.58900e+00],\n",
       "       [7.25000e+02, 3.18000e+01, 3.50000e+01, 4.09000e+01, 1.63600e+01,\n",
       "        6.05320e+00],\n",
       "       [7.20000e+02, 3.20000e+01, 3.50000e+01, 4.06000e+01, 1.63618e+01,\n",
       "        6.09000e+00],\n",
       "       [7.14000e+02, 3.27000e+01, 3.60000e+01, 4.15000e+01, 1.65170e+01,\n",
       "        5.85150e+00],\n",
       "       [8.50000e+02, 3.28000e+01, 3.60000e+01, 4.16000e+01, 1.68896e+01,\n",
       "        6.19840e+00],\n",
       "       [1.00000e+03, 3.35000e+01, 3.70000e+01, 4.26000e+01, 1.89570e+01,\n",
       "        6.60300e+00],\n",
       "       [9.20000e+02, 3.50000e+01, 3.85000e+01, 4.41000e+01, 1.80369e+01,\n",
       "        6.30630e+00],\n",
       "       [9.55000e+02, 3.50000e+01, 3.85000e+01, 4.40000e+01, 1.80840e+01,\n",
       "        6.29200e+00],\n",
       "       [9.25000e+02, 3.62000e+01, 3.95000e+01, 4.53000e+01, 1.87542e+01,\n",
       "        6.74970e+00],\n",
       "       [9.75000e+02, 3.74000e+01, 4.10000e+01, 4.59000e+01, 1.86354e+01,\n",
       "        6.74730e+00],\n",
       "       [9.50000e+02, 3.80000e+01, 4.10000e+01, 4.65000e+01, 1.76235e+01,\n",
       "        6.37050e+00],\n",
       "       [4.00000e+01, 1.29000e+01, 1.41000e+01, 1.62000e+01, 4.14720e+00,\n",
       "        2.26800e+00],\n",
       "       [6.90000e+01, 1.65000e+01, 1.82000e+01, 2.03000e+01, 5.29830e+00,\n",
       "        2.82170e+00],\n",
       "       [7.80000e+01, 1.75000e+01, 1.88000e+01, 2.12000e+01, 5.57560e+00,\n",
       "        2.90440e+00],\n",
       "       [8.70000e+01, 1.82000e+01, 1.98000e+01, 2.22000e+01, 5.61660e+00,\n",
       "        3.17460e+00],\n",
       "       [1.20000e+02, 1.86000e+01, 2.00000e+01, 2.22000e+01, 6.21600e+00,\n",
       "        3.57420e+00],\n",
       "       [0.00000e+00, 1.90000e+01, 2.05000e+01, 2.28000e+01, 6.47520e+00,\n",
       "        3.35160e+00],\n",
       "       [1.10000e+02, 1.91000e+01, 2.08000e+01, 2.31000e+01, 6.16770e+00,\n",
       "        3.39570e+00],\n",
       "       [1.20000e+02, 1.94000e+01, 2.10000e+01, 2.37000e+01, 6.11460e+00,\n",
       "        3.29430e+00],\n",
       "       [1.50000e+02, 2.04000e+01, 2.20000e+01, 2.47000e+01, 5.80450e+00,\n",
       "        3.75440e+00],\n",
       "       [1.45000e+02, 2.05000e+01, 2.20000e+01, 2.43000e+01, 6.63390e+00,\n",
       "        3.54780e+00],\n",
       "       [1.60000e+02, 2.05000e+01, 2.25000e+01, 2.53000e+01, 7.03340e+00,\n",
       "        3.82030e+00],\n",
       "       [1.40000e+02, 2.10000e+01, 2.25000e+01, 2.50000e+01, 6.55000e+00,\n",
       "        3.32500e+00],\n",
       "       [1.60000e+02, 2.11000e+01, 2.25000e+01, 2.50000e+01, 6.40000e+00,\n",
       "        3.80000e+00],\n",
       "       [1.69000e+02, 2.20000e+01, 2.40000e+01, 2.72000e+01, 7.53440e+00,\n",
       "        3.83520e+00],\n",
       "       [1.61000e+02, 2.20000e+01, 2.34000e+01, 2.67000e+01, 6.91530e+00,\n",
       "        3.63120e+00],\n",
       "       [2.00000e+02, 2.21000e+01, 2.35000e+01, 2.68000e+01, 7.39680e+00,\n",
       "        4.12720e+00],\n",
       "       [1.80000e+02, 2.36000e+01, 2.52000e+01, 2.79000e+01, 7.08660e+00,\n",
       "        3.90600e+00],\n",
       "       [2.90000e+02, 2.40000e+01, 2.60000e+01, 2.92000e+01, 8.87680e+00,\n",
       "        4.49680e+00],\n",
       "       [2.72000e+02, 2.50000e+01, 2.70000e+01, 3.06000e+01, 8.56800e+00,\n",
       "        4.77360e+00],\n",
       "       [3.90000e+02, 2.95000e+01, 3.17000e+01, 3.50000e+01, 9.48500e+00,\n",
       "        5.35500e+00],\n",
       "       [2.70000e+02, 2.36000e+01, 2.60000e+01, 2.87000e+01, 8.38040e+00,\n",
       "        4.24760e+00],\n",
       "       [2.70000e+02, 2.41000e+01, 2.65000e+01, 2.93000e+01, 8.14540e+00,\n",
       "        4.24850e+00],\n",
       "       [3.06000e+02, 2.56000e+01, 2.80000e+01, 3.08000e+01, 8.77800e+00,\n",
       "        4.68160e+00],\n",
       "       [5.40000e+02, 2.85000e+01, 3.10000e+01, 3.40000e+01, 1.07440e+01,\n",
       "        6.56200e+00],\n",
       "       [8.00000e+02, 3.37000e+01, 3.64000e+01, 3.96000e+01, 1.17612e+01,\n",
       "        6.57360e+00],\n",
       "       [1.00000e+03, 3.73000e+01, 4.00000e+01, 4.35000e+01, 1.23540e+01,\n",
       "        6.52500e+00],\n",
       "       [5.50000e+01, 1.35000e+01, 1.47000e+01, 1.65000e+01, 6.84750e+00,\n",
       "        2.32650e+00],\n",
       "       [6.00000e+01, 1.43000e+01, 1.55000e+01, 1.74000e+01, 6.57720e+00,\n",
       "        2.31420e+00],\n",
       "       [9.00000e+01, 1.63000e+01, 1.77000e+01, 1.98000e+01, 7.40520e+00,\n",
       "        2.67300e+00],\n",
       "       [1.20000e+02, 1.75000e+01, 1.90000e+01, 2.13000e+01, 8.39220e+00,\n",
       "        2.91810e+00],\n",
       "       [1.50000e+02, 1.84000e+01, 2.00000e+01, 2.24000e+01, 8.89280e+00,\n",
       "        3.29280e+00],\n",
       "       [1.40000e+02, 1.90000e+01, 2.07000e+01, 2.32000e+01, 8.53760e+00,\n",
       "        3.29440e+00],\n",
       "       [1.70000e+02, 1.90000e+01, 2.07000e+01, 2.32000e+01, 9.39600e+00,\n",
       "        3.41040e+00],\n",
       "       [1.45000e+02, 1.98000e+01, 2.15000e+01, 2.41000e+01, 9.73640e+00,\n",
       "        3.15710e+00],\n",
       "       [2.00000e+02, 2.12000e+01, 2.30000e+01, 2.58000e+01, 1.03458e+01,\n",
       "        3.66360e+00],\n",
       "       [2.73000e+02, 2.30000e+01, 2.50000e+01, 2.80000e+01, 1.10880e+01,\n",
       "        4.14400e+00],\n",
       "       [3.00000e+02, 2.40000e+01, 2.60000e+01, 2.90000e+01, 1.13680e+01,\n",
       "        4.23400e+00],\n",
       "       [5.90000e+00, 7.50000e+00, 8.40000e+00, 8.80000e+00, 2.11200e+00,\n",
       "        1.40800e+00],\n",
       "       [3.20000e+01, 1.25000e+01, 1.37000e+01, 1.47000e+01, 3.52800e+00,\n",
       "        1.99920e+00],\n",
       "       [4.00000e+01, 1.38000e+01, 1.50000e+01, 1.60000e+01, 3.82400e+00,\n",
       "        2.43200e+00],\n",
       "       [5.15000e+01, 1.50000e+01, 1.62000e+01, 1.72000e+01, 4.59240e+00,\n",
       "        2.63160e+00],\n",
       "       [7.00000e+01, 1.57000e+01, 1.74000e+01, 1.85000e+01, 4.58800e+00,\n",
       "        2.94150e+00],\n",
       "       [1.00000e+02, 1.62000e+01, 1.80000e+01, 1.92000e+01, 5.22240e+00,\n",
       "        3.32160e+00],\n",
       "       [7.80000e+01, 1.68000e+01, 1.87000e+01, 1.94000e+01, 5.19920e+00,\n",
       "        3.12340e+00],\n",
       "       [8.00000e+01, 1.72000e+01, 1.90000e+01, 2.02000e+01, 5.63580e+00,\n",
       "        3.05020e+00],\n",
       "       [8.50000e+01, 1.78000e+01, 1.96000e+01, 2.08000e+01, 5.13760e+00,\n",
       "        3.03680e+00],\n",
       "       [8.50000e+01, 1.82000e+01, 2.00000e+01, 2.10000e+01, 5.08200e+00,\n",
       "        2.77200e+00],\n",
       "       [1.10000e+02, 1.90000e+01, 2.10000e+01, 2.25000e+01, 5.69250e+00,\n",
       "        3.55500e+00],\n",
       "       [1.15000e+02, 1.90000e+01, 2.10000e+01, 2.25000e+01, 5.91750e+00,\n",
       "        3.30750e+00],\n",
       "       [1.25000e+02, 1.90000e+01, 2.10000e+01, 2.25000e+01, 5.69250e+00,\n",
       "        3.66750e+00],\n",
       "       [1.30000e+02, 1.93000e+01, 2.13000e+01, 2.28000e+01, 6.38400e+00,\n",
       "        3.53400e+00],\n",
       "       [1.20000e+02, 2.00000e+01, 2.20000e+01, 2.35000e+01, 6.11000e+00,\n",
       "        3.40750e+00],\n",
       "       [1.20000e+02, 2.00000e+01, 2.20000e+01, 2.35000e+01, 5.64000e+00,\n",
       "        3.52500e+00],\n",
       "       [1.30000e+02, 2.00000e+01, 2.20000e+01, 2.35000e+01, 6.11000e+00,\n",
       "        3.52500e+00],\n",
       "       [1.35000e+02, 2.00000e+01, 2.20000e+01, 2.35000e+01, 5.87500e+00,\n",
       "        3.52500e+00],\n",
       "       [1.10000e+02, 2.00000e+01, 2.20000e+01, 2.35000e+01, 5.52250e+00,\n",
       "        3.99500e+00],\n",
       "       [1.30000e+02, 2.05000e+01, 2.25000e+01, 2.40000e+01, 5.85600e+00,\n",
       "        3.62400e+00],\n",
       "       [1.50000e+02, 2.05000e+01, 2.25000e+01, 2.40000e+01, 6.79200e+00,\n",
       "        3.62400e+00],\n",
       "       [1.45000e+02, 2.07000e+01, 2.27000e+01, 2.42000e+01, 5.95320e+00,\n",
       "        3.63000e+00],\n",
       "       [1.50000e+02, 2.10000e+01, 2.30000e+01, 2.45000e+01, 5.21850e+00,\n",
       "        3.62600e+00],\n",
       "       [1.70000e+02, 2.15000e+01, 2.35000e+01, 2.50000e+01, 6.27500e+00,\n",
       "        3.72500e+00],\n",
       "       [2.25000e+02, 2.20000e+01, 2.40000e+01, 2.55000e+01, 7.29300e+00,\n",
       "        3.72300e+00],\n",
       "       [1.45000e+02, 2.20000e+01, 2.40000e+01, 2.55000e+01, 6.37500e+00,\n",
       "        3.82500e+00],\n",
       "       [1.88000e+02, 2.26000e+01, 2.46000e+01, 2.62000e+01, 6.73340e+00,\n",
       "        4.16580e+00],\n",
       "       [1.80000e+02, 2.30000e+01, 2.50000e+01, 2.65000e+01, 6.43950e+00,\n",
       "        3.68350e+00],\n",
       "       [1.97000e+02, 2.35000e+01, 2.56000e+01, 2.70000e+01, 6.56100e+00,\n",
       "        4.23900e+00],\n",
       "       [2.18000e+02, 2.50000e+01, 2.65000e+01, 2.80000e+01, 7.16800e+00,\n",
       "        4.14400e+00],\n",
       "       [3.00000e+02, 2.52000e+01, 2.73000e+01, 2.87000e+01, 8.32300e+00,\n",
       "        5.13730e+00],\n",
       "       [2.60000e+02, 2.54000e+01, 2.75000e+01, 2.89000e+01, 7.16720e+00,\n",
       "        4.33500e+00],\n",
       "       [2.65000e+02, 2.54000e+01, 2.75000e+01, 2.89000e+01, 7.05160e+00,\n",
       "        4.33500e+00],\n",
       "       [2.50000e+02, 2.54000e+01, 2.75000e+01, 2.89000e+01, 7.28280e+00,\n",
       "        4.56620e+00],\n",
       "       [2.50000e+02, 2.59000e+01, 2.80000e+01, 2.94000e+01, 7.82040e+00,\n",
       "        4.20420e+00],\n",
       "       [3.00000e+02, 2.69000e+01, 2.87000e+01, 3.01000e+01, 7.58520e+00,\n",
       "        4.63540e+00],\n",
       "       [3.20000e+02, 2.78000e+01, 3.00000e+01, 3.16000e+01, 7.61560e+00,\n",
       "        4.77160e+00],\n",
       "       [5.14000e+02, 3.05000e+01, 3.28000e+01, 3.40000e+01, 1.00300e+01,\n",
       "        6.01800e+00],\n",
       "       [5.56000e+02, 3.20000e+01, 3.45000e+01, 3.65000e+01, 1.02565e+01,\n",
       "        6.38750e+00],\n",
       "       [8.40000e+02, 3.25000e+01, 3.50000e+01, 3.73000e+01, 1.14884e+01,\n",
       "        7.79570e+00],\n",
       "       [6.85000e+02, 3.40000e+01, 3.65000e+01, 3.90000e+01, 1.08810e+01,\n",
       "        6.86400e+00],\n",
       "       [7.00000e+02, 3.40000e+01, 3.60000e+01, 3.83000e+01, 1.06091e+01,\n",
       "        6.74080e+00],\n",
       "       [7.00000e+02, 3.45000e+01, 3.70000e+01, 3.94000e+01, 1.08350e+01,\n",
       "        6.26460e+00],\n",
       "       [6.90000e+02, 3.46000e+01, 3.70000e+01, 3.93000e+01, 1.05717e+01,\n",
       "        6.36660e+00],\n",
       "       [9.00000e+02, 3.65000e+01, 3.90000e+01, 4.14000e+01, 1.11366e+01,\n",
       "        7.49340e+00],\n",
       "       [6.50000e+02, 3.65000e+01, 3.90000e+01, 4.14000e+01, 1.11366e+01,\n",
       "        6.00300e+00],\n",
       "       [8.20000e+02, 3.66000e+01, 3.90000e+01, 4.13000e+01, 1.24313e+01,\n",
       "        7.35140e+00],\n",
       "       [8.50000e+02, 3.69000e+01, 4.00000e+01, 4.23000e+01, 1.19286e+01,\n",
       "        7.10640e+00],\n",
       "       [9.00000e+02, 3.70000e+01, 4.00000e+01, 4.25000e+01, 1.17300e+01,\n",
       "        7.22500e+00],\n",
       "       [1.01500e+03, 3.70000e+01, 4.00000e+01, 4.24000e+01, 1.23808e+01,\n",
       "        7.46240e+00],\n",
       "       [8.20000e+02, 3.71000e+01, 4.00000e+01, 4.25000e+01, 1.11350e+01,\n",
       "        6.63000e+00],\n",
       "       [1.10000e+03, 3.90000e+01, 4.20000e+01, 4.46000e+01, 1.28002e+01,\n",
       "        6.86840e+00],\n",
       "       [1.00000e+03, 3.98000e+01, 4.30000e+01, 4.52000e+01, 1.19328e+01,\n",
       "        7.27720e+00],\n",
       "       [1.10000e+03, 4.01000e+01, 4.30000e+01, 4.55000e+01, 1.25125e+01,\n",
       "        7.41650e+00],\n",
       "       [1.00000e+03, 4.02000e+01, 4.35000e+01, 4.60000e+01, 1.26040e+01,\n",
       "        8.14200e+00],\n",
       "       [1.00000e+03, 4.11000e+01, 4.40000e+01, 4.66000e+01, 1.24888e+01,\n",
       "        7.59580e+00],\n",
       "       [2.00000e+02, 3.00000e+01, 3.23000e+01, 3.48000e+01, 5.56800e+00,\n",
       "        3.37560e+00],\n",
       "       [3.00000e+02, 3.17000e+01, 3.40000e+01, 3.78000e+01, 5.70780e+00,\n",
       "        4.15800e+00],\n",
       "       [3.00000e+02, 3.27000e+01, 3.50000e+01, 3.88000e+01, 5.93640e+00,\n",
       "        4.38440e+00],\n",
       "       [3.00000e+02, 3.48000e+01, 3.73000e+01, 3.98000e+01, 6.28840e+00,\n",
       "        4.01980e+00],\n",
       "       [4.30000e+02, 3.55000e+01, 3.80000e+01, 4.05000e+01, 7.29000e+00,\n",
       "        4.57650e+00],\n",
       "       [3.45000e+02, 3.60000e+01, 3.85000e+01, 4.10000e+01, 6.39600e+00,\n",
       "        3.97700e+00],\n",
       "       [4.56000e+02, 4.00000e+01, 4.25000e+01, 4.55000e+01, 7.28000e+00,\n",
       "        4.32250e+00],\n",
       "       [5.10000e+02, 4.00000e+01, 4.25000e+01, 4.55000e+01, 6.82500e+00,\n",
       "        4.45900e+00],\n",
       "       [5.40000e+02, 4.01000e+01, 4.30000e+01, 4.58000e+01, 7.78600e+00,\n",
       "        5.12960e+00],\n",
       "       [5.00000e+02, 4.20000e+01, 4.50000e+01, 4.80000e+01, 6.96000e+00,\n",
       "        4.89600e+00],\n",
       "       [5.67000e+02, 4.32000e+01, 4.60000e+01, 4.87000e+01, 7.79200e+00,\n",
       "        4.87000e+00],\n",
       "       [7.70000e+02, 4.48000e+01, 4.80000e+01, 5.12000e+01, 7.68000e+00,\n",
       "        5.37600e+00],\n",
       "       [9.50000e+02, 4.83000e+01, 5.17000e+01, 5.51000e+01, 8.92620e+00,\n",
       "        6.17120e+00],\n",
       "       [1.25000e+03, 5.20000e+01, 5.60000e+01, 5.97000e+01, 1.06863e+01,\n",
       "        6.98490e+00],\n",
       "       [1.60000e+03, 5.60000e+01, 6.00000e+01, 6.40000e+01, 9.60000e+00,\n",
       "        6.14400e+00],\n",
       "       [1.55000e+03, 5.60000e+01, 6.00000e+01, 6.40000e+01, 9.60000e+00,\n",
       "        6.14400e+00],\n",
       "       [1.65000e+03, 5.90000e+01, 6.34000e+01, 6.80000e+01, 1.08120e+01,\n",
       "        7.48000e+00],\n",
       "       [6.70000e+00, 9.30000e+00, 9.80000e+00, 1.08000e+01, 1.73880e+00,\n",
       "        1.04760e+00],\n",
       "       [7.50000e+00, 1.00000e+01, 1.05000e+01, 1.16000e+01, 1.97200e+00,\n",
       "        1.16000e+00],\n",
       "       [7.00000e+00, 1.01000e+01, 1.06000e+01, 1.16000e+01, 1.72840e+00,\n",
       "        1.14840e+00],\n",
       "       [9.70000e+00, 1.04000e+01, 1.10000e+01, 1.20000e+01, 2.19600e+00,\n",
       "        1.38000e+00],\n",
       "       [9.80000e+00, 1.07000e+01, 1.12000e+01, 1.24000e+01, 2.08320e+00,\n",
       "        1.27720e+00],\n",
       "       [8.70000e+00, 1.08000e+01, 1.13000e+01, 1.26000e+01, 1.97820e+00,\n",
       "        1.28520e+00],\n",
       "       [1.00000e+01, 1.13000e+01, 1.18000e+01, 1.31000e+01, 2.21390e+00,\n",
       "        1.28380e+00],\n",
       "       [9.90000e+00, 1.13000e+01, 1.18000e+01, 1.31000e+01, 2.21390e+00,\n",
       "        1.16590e+00],\n",
       "       [9.80000e+00, 1.14000e+01, 1.20000e+01, 1.32000e+01, 2.20440e+00,\n",
       "        1.14840e+00],\n",
       "       [1.22000e+01, 1.15000e+01, 1.22000e+01, 1.34000e+01, 2.09040e+00,\n",
       "        1.39360e+00],\n",
       "       [1.34000e+01, 1.17000e+01, 1.24000e+01, 1.35000e+01, 2.43000e+00,\n",
       "        1.26900e+00],\n",
       "       [1.22000e+01, 1.21000e+01, 1.30000e+01, 1.38000e+01, 2.27700e+00,\n",
       "        1.25580e+00],\n",
       "       [1.97000e+01, 1.32000e+01, 1.43000e+01, 1.52000e+01, 2.87280e+00,\n",
       "        2.06720e+00],\n",
       "       [1.99000e+01, 1.38000e+01, 1.50000e+01, 1.62000e+01, 2.93220e+00,\n",
       "        1.87920e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Bream'],\n",
       "       ['Roach'],\n",
       "       ['Roach'],\n",
       "       ['Roach'],\n",
       "       ['Roach'],\n",
       "       ['Roach'],\n",
       "       ['Roach'],\n",
       "       ['Roach'],\n",
       "       ['Roach'],\n",
       "       ['Roach'],\n",
       "       ['Roach'],\n",
       "       ['Roach'],\n",
       "       ['Roach'],\n",
       "       ['Roach'],\n",
       "       ['Roach'],\n",
       "       ['Roach'],\n",
       "       ['Roach'],\n",
       "       ['Roach'],\n",
       "       ['Roach'],\n",
       "       ['Roach'],\n",
       "       ['Roach'],\n",
       "       ['Whitefish'],\n",
       "       ['Whitefish'],\n",
       "       ['Whitefish'],\n",
       "       ['Whitefish'],\n",
       "       ['Whitefish'],\n",
       "       ['Whitefish'],\n",
       "       ['Parkki'],\n",
       "       ['Parkki'],\n",
       "       ['Parkki'],\n",
       "       ['Parkki'],\n",
       "       ['Parkki'],\n",
       "       ['Parkki'],\n",
       "       ['Parkki'],\n",
       "       ['Parkki'],\n",
       "       ['Parkki'],\n",
       "       ['Parkki'],\n",
       "       ['Parkki'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Perch'],\n",
       "       ['Pike'],\n",
       "       ['Pike'],\n",
       "       ['Pike'],\n",
       "       ['Pike'],\n",
       "       ['Pike'],\n",
       "       ['Pike'],\n",
       "       ['Pike'],\n",
       "       ['Pike'],\n",
       "       ['Pike'],\n",
       "       ['Pike'],\n",
       "       ['Pike'],\n",
       "       ['Pike'],\n",
       "       ['Pike'],\n",
       "       ['Pike'],\n",
       "       ['Pike'],\n",
       "       ['Pike'],\n",
       "       ['Pike'],\n",
       "       ['Smelt'],\n",
       "       ['Smelt'],\n",
       "       ['Smelt'],\n",
       "       ['Smelt'],\n",
       "       ['Smelt'],\n",
       "       ['Smelt'],\n",
       "       ['Smelt'],\n",
       "       ['Smelt'],\n",
       "       ['Smelt'],\n",
       "       ['Smelt'],\n",
       "       ['Smelt'],\n",
       "       ['Smelt'],\n",
       "       ['Smelt'],\n",
       "       ['Smelt']], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0 - Bream, 1 - Pakki, 2 - perch, 3 - pike, 4 - rouch, 5 - smelt, 6 - whitefish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer([(\"oh\", OneHotEncoder(),[0])], remainder = \"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ct.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159, 7)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119, 6)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119, 7)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bream', 'Roach', 'Whitefish', 'Parkki', 'Perch', 'Pike', 'Smelt'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Species\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical.add(Dense(units = 6, kernel_initializer = \"random_uniform\", activation = \"relu\"))\n",
    "categorical.add(Dropout(0.2))\n",
    "categorical.add(Dense(units = 10, kernel_initializer = \"random_uniform\", activation = \"relu\"))\n",
    "categorical.add(Dropout(0.2))\n",
    "categorical.add(Dense(units = 10, kernel_initializer = \"random_uniform\", activation = \"relu\"))\n",
    "categorical.add(Dense(units = 7, kernel_initializer = \"random_uniform\", activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical.compile(optimizer = \"rmsprop\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2500\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 1.9451 - accuracy: 0.2269 - val_loss: 1.9430 - val_accuracy: 0.3000\n",
      "Epoch 2/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.9423 - accuracy: 0.3445 - val_loss: 1.9411 - val_accuracy: 0.3000\n",
      "Epoch 3/2500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.9401 - accuracy: 0.3697 - val_loss: 1.9393 - val_accuracy: 0.3000\n",
      "Epoch 4/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.9382 - accuracy: 0.3697 - val_loss: 1.9376 - val_accuracy: 0.3000\n",
      "Epoch 5/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9363 - accuracy: 0.3697 - val_loss: 1.9360 - val_accuracy: 0.3000\n",
      "Epoch 6/2500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.9346 - accuracy: 0.3697 - val_loss: 1.9345 - val_accuracy: 0.3000\n",
      "Epoch 7/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9328 - accuracy: 0.3697 - val_loss: 1.9330 - val_accuracy: 0.3000\n",
      "Epoch 8/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9311 - accuracy: 0.3697 - val_loss: 1.9315 - val_accuracy: 0.3000\n",
      "Epoch 9/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.9294 - accuracy: 0.3697 - val_loss: 1.9299 - val_accuracy: 0.3000\n",
      "Epoch 10/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9277 - accuracy: 0.3697 - val_loss: 1.9284 - val_accuracy: 0.3000\n",
      "Epoch 11/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.9260 - accuracy: 0.3697 - val_loss: 1.9269 - val_accuracy: 0.3000\n",
      "Epoch 12/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9242 - accuracy: 0.3697 - val_loss: 1.9253 - val_accuracy: 0.3000\n",
      "Epoch 13/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9223 - accuracy: 0.3697 - val_loss: 1.9237 - val_accuracy: 0.3000\n",
      "Epoch 14/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9205 - accuracy: 0.3697 - val_loss: 1.9221 - val_accuracy: 0.3000\n",
      "Epoch 15/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.9187 - accuracy: 0.3697 - val_loss: 1.9204 - val_accuracy: 0.3000\n",
      "Epoch 16/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.9169 - accuracy: 0.3697 - val_loss: 1.9187 - val_accuracy: 0.3000\n",
      "Epoch 17/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.9149 - accuracy: 0.3697 - val_loss: 1.9170 - val_accuracy: 0.3000\n",
      "Epoch 18/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9129 - accuracy: 0.3697 - val_loss: 1.9153 - val_accuracy: 0.3000\n",
      "Epoch 19/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9107 - accuracy: 0.3697 - val_loss: 1.9135 - val_accuracy: 0.3000\n",
      "Epoch 20/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9086 - accuracy: 0.3697 - val_loss: 1.9117 - val_accuracy: 0.3000\n",
      "Epoch 21/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9064 - accuracy: 0.3697 - val_loss: 1.9098 - val_accuracy: 0.3000\n",
      "Epoch 22/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.9047 - accuracy: 0.3697 - val_loss: 1.9079 - val_accuracy: 0.3000\n",
      "Epoch 23/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.9025 - accuracy: 0.3697 - val_loss: 1.9059 - val_accuracy: 0.3000\n",
      "Epoch 24/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9001 - accuracy: 0.3697 - val_loss: 1.9039 - val_accuracy: 0.3000\n",
      "Epoch 25/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.8979 - accuracy: 0.3697 - val_loss: 1.9019 - val_accuracy: 0.3000\n",
      "Epoch 26/2500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.8951 - accuracy: 0.3697 - val_loss: 1.8997 - val_accuracy: 0.3000\n",
      "Epoch 27/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.8932 - accuracy: 0.3697 - val_loss: 1.8976 - val_accuracy: 0.3000\n",
      "Epoch 28/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.8901 - accuracy: 0.3697 - val_loss: 1.8954 - val_accuracy: 0.3000\n",
      "Epoch 29/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.8872 - accuracy: 0.3697 - val_loss: 1.8930 - val_accuracy: 0.3000\n",
      "Epoch 30/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.8850 - accuracy: 0.3697 - val_loss: 1.8907 - val_accuracy: 0.3000\n",
      "Epoch 31/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.8831 - accuracy: 0.3697 - val_loss: 1.8883 - val_accuracy: 0.3000\n",
      "Epoch 32/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.8786 - accuracy: 0.3697 - val_loss: 1.8858 - val_accuracy: 0.3000\n",
      "Epoch 33/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.8762 - accuracy: 0.3697 - val_loss: 1.8833 - val_accuracy: 0.3000\n",
      "Epoch 34/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8732 - accuracy: 0.3697 - val_loss: 1.8808 - val_accuracy: 0.3000\n",
      "Epoch 35/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.8693 - accuracy: 0.3697 - val_loss: 1.8781 - val_accuracy: 0.3000\n",
      "Epoch 36/2500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.8663 - accuracy: 0.3697 - val_loss: 1.8755 - val_accuracy: 0.3000\n",
      "Epoch 37/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8638 - accuracy: 0.3697 - val_loss: 1.8727 - val_accuracy: 0.3000\n",
      "Epoch 38/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.8602 - accuracy: 0.3697 - val_loss: 1.8701 - val_accuracy: 0.3000\n",
      "Epoch 39/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.8592 - accuracy: 0.3697 - val_loss: 1.8674 - val_accuracy: 0.3000\n",
      "Epoch 40/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.8521 - accuracy: 0.3697 - val_loss: 1.8645 - val_accuracy: 0.3000\n",
      "Epoch 41/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8498 - accuracy: 0.3697 - val_loss: 1.8615 - val_accuracy: 0.3000\n",
      "Epoch 42/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.8466 - accuracy: 0.3697 - val_loss: 1.8588 - val_accuracy: 0.3000\n",
      "Epoch 43/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8450 - accuracy: 0.3697 - val_loss: 1.8560 - val_accuracy: 0.3000\n",
      "Epoch 44/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.8400 - accuracy: 0.3697 - val_loss: 1.8532 - val_accuracy: 0.3000\n",
      "Epoch 45/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.8365 - accuracy: 0.3697 - val_loss: 1.8503 - val_accuracy: 0.3000\n",
      "Epoch 46/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8323 - accuracy: 0.3697 - val_loss: 1.8475 - val_accuracy: 0.3000\n",
      "Epoch 47/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.8288 - accuracy: 0.3697 - val_loss: 1.8445 - val_accuracy: 0.3000\n",
      "Epoch 48/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.8235 - accuracy: 0.3697 - val_loss: 1.8416 - val_accuracy: 0.3000\n",
      "Epoch 49/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8201 - accuracy: 0.3697 - val_loss: 1.8385 - val_accuracy: 0.3000\n",
      "Epoch 50/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.8153 - accuracy: 0.3697 - val_loss: 1.8355 - val_accuracy: 0.3000\n",
      "Epoch 51/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8096 - accuracy: 0.3697 - val_loss: 1.8326 - val_accuracy: 0.3000\n",
      "Epoch 52/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.8058 - accuracy: 0.3697 - val_loss: 1.8296 - val_accuracy: 0.3000\n",
      "Epoch 53/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.8049 - accuracy: 0.3697 - val_loss: 1.8267 - val_accuracy: 0.3000\n",
      "Epoch 54/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.7996 - accuracy: 0.3697 - val_loss: 1.8239 - val_accuracy: 0.3000\n",
      "Epoch 55/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.7979 - accuracy: 0.3697 - val_loss: 1.8214 - val_accuracy: 0.3000\n",
      "Epoch 56/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.7907 - accuracy: 0.3697 - val_loss: 1.8186 - val_accuracy: 0.3000\n",
      "Epoch 57/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7892 - accuracy: 0.3697 - val_loss: 1.8161 - val_accuracy: 0.3000\n",
      "Epoch 58/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7889 - accuracy: 0.3697 - val_loss: 1.8136 - val_accuracy: 0.3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7916 - accuracy: 0.3697 - val_loss: 1.8115 - val_accuracy: 0.3000\n",
      "Epoch 60/2500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.7784 - accuracy: 0.3697 - val_loss: 1.8090 - val_accuracy: 0.3000\n",
      "Epoch 61/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.7728 - accuracy: 0.3697 - val_loss: 1.8067 - val_accuracy: 0.3000\n",
      "Epoch 62/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7761 - accuracy: 0.3697 - val_loss: 1.8048 - val_accuracy: 0.3000\n",
      "Epoch 63/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7557 - accuracy: 0.3697 - val_loss: 1.8027 - val_accuracy: 0.3000\n",
      "Epoch 64/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7599 - accuracy: 0.3697 - val_loss: 1.8005 - val_accuracy: 0.3000\n",
      "Epoch 65/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.7789 - accuracy: 0.3697 - val_loss: 1.7997 - val_accuracy: 0.3000\n",
      "Epoch 66/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7546 - accuracy: 0.3697 - val_loss: 1.7979 - val_accuracy: 0.3000\n",
      "Epoch 67/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.7626 - accuracy: 0.3697 - val_loss: 1.7963 - val_accuracy: 0.3000\n",
      "Epoch 68/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.7452 - accuracy: 0.3697 - val_loss: 1.7947 - val_accuracy: 0.3000\n",
      "Epoch 69/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.7456 - accuracy: 0.3697 - val_loss: 1.7932 - val_accuracy: 0.3000\n",
      "Epoch 70/2500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.7495 - accuracy: 0.3697 - val_loss: 1.7921 - val_accuracy: 0.3000\n",
      "Epoch 71/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7428 - accuracy: 0.3697 - val_loss: 1.7910 - val_accuracy: 0.3000\n",
      "Epoch 72/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7377 - accuracy: 0.3697 - val_loss: 1.7900 - val_accuracy: 0.3000\n",
      "Epoch 73/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.7351 - accuracy: 0.3697 - val_loss: 1.7893 - val_accuracy: 0.3000\n",
      "Epoch 74/2500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.7381 - accuracy: 0.3697 - val_loss: 1.7889 - val_accuracy: 0.3000\n",
      "Epoch 75/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7276 - accuracy: 0.3697 - val_loss: 1.7885 - val_accuracy: 0.3000\n",
      "Epoch 76/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7330 - accuracy: 0.3697 - val_loss: 1.7882 - val_accuracy: 0.3000\n",
      "Epoch 77/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.7275 - accuracy: 0.3697 - val_loss: 1.7885 - val_accuracy: 0.3000\n",
      "Epoch 78/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7171 - accuracy: 0.3697 - val_loss: 1.7886 - val_accuracy: 0.3000\n",
      "Epoch 79/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7280 - accuracy: 0.3697 - val_loss: 1.7890 - val_accuracy: 0.3000\n",
      "Epoch 80/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.7116 - accuracy: 0.3697 - val_loss: 1.7892 - val_accuracy: 0.3000\n",
      "Epoch 81/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7255 - accuracy: 0.3697 - val_loss: 1.7894 - val_accuracy: 0.3000\n",
      "Epoch 82/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7657 - accuracy: 0.34 - 0s 17ms/step - loss: 1.7180 - accuracy: 0.3697 - val_loss: 1.7900 - val_accuracy: 0.3000\n",
      "Epoch 83/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.7190 - accuracy: 0.3697 - val_loss: 1.7902 - val_accuracy: 0.3000\n",
      "Epoch 84/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7329 - accuracy: 0.3697 - val_loss: 1.7908 - val_accuracy: 0.3000\n",
      "Epoch 85/2500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.7105 - accuracy: 0.3697 - val_loss: 1.7915 - val_accuracy: 0.3000\n",
      "Epoch 86/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.7146 - accuracy: 0.3697 - val_loss: 1.7919 - val_accuracy: 0.3000\n",
      "Epoch 87/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7225 - accuracy: 0.3697 - val_loss: 1.7925 - val_accuracy: 0.3000\n",
      "Epoch 88/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7128 - accuracy: 0.3697 - val_loss: 1.7929 - val_accuracy: 0.3000\n",
      "Epoch 89/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6979 - accuracy: 0.3697 - val_loss: 1.7940 - val_accuracy: 0.3000\n",
      "Epoch 90/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.7160 - accuracy: 0.3697 - val_loss: 1.7951 - val_accuracy: 0.3000\n",
      "Epoch 91/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7206 - accuracy: 0.3697 - val_loss: 1.7957 - val_accuracy: 0.3000\n",
      "Epoch 92/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7117 - accuracy: 0.3697 - val_loss: 1.7961 - val_accuracy: 0.3000\n",
      "Epoch 93/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.7152 - accuracy: 0.3697 - val_loss: 1.7974 - val_accuracy: 0.3000\n",
      "Epoch 94/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.7003 - accuracy: 0.3697 - val_loss: 1.7988 - val_accuracy: 0.3000\n",
      "Epoch 95/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6996 - accuracy: 0.3697 - val_loss: 1.7999 - val_accuracy: 0.3000\n",
      "Epoch 96/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.7084 - accuracy: 0.3697 - val_loss: 1.8010 - val_accuracy: 0.3000\n",
      "Epoch 97/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.7073 - accuracy: 0.3697 - val_loss: 1.8024 - val_accuracy: 0.3000\n",
      "Epoch 98/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.7153 - accuracy: 0.3697 - val_loss: 1.8025 - val_accuracy: 0.3000\n",
      "Epoch 99/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6980 - accuracy: 0.3697 - val_loss: 1.8034 - val_accuracy: 0.3000\n",
      "Epoch 100/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7038 - accuracy: 0.3697 - val_loss: 1.8042 - val_accuracy: 0.3000\n",
      "Epoch 101/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7029 - accuracy: 0.3697 - val_loss: 1.8048 - val_accuracy: 0.3000\n",
      "Epoch 102/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7190 - accuracy: 0.3697 - val_loss: 1.8045 - val_accuracy: 0.3000\n",
      "Epoch 103/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6974 - accuracy: 0.3697 - val_loss: 1.8054 - val_accuracy: 0.3000\n",
      "Epoch 104/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.7030 - accuracy: 0.3697 - val_loss: 1.8066 - val_accuracy: 0.3000\n",
      "Epoch 105/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.7270 - accuracy: 0.3697 - val_loss: 1.8060 - val_accuracy: 0.3000\n",
      "Epoch 106/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.7176 - accuracy: 0.3697 - val_loss: 1.8062 - val_accuracy: 0.3000\n",
      "Epoch 107/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7192 - accuracy: 0.3697 - val_loss: 1.8064 - val_accuracy: 0.3000\n",
      "Epoch 108/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7035 - accuracy: 0.3697 - val_loss: 1.8067 - val_accuracy: 0.3000\n",
      "Epoch 109/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6927 - accuracy: 0.3697 - val_loss: 1.8075 - val_accuracy: 0.3000\n",
      "Epoch 110/2500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7048 - accuracy: 0.3697 - val_loss: 1.8078 - val_accuracy: 0.3000\n",
      "Epoch 111/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.7248 - accuracy: 0.3697 - val_loss: 1.8074 - val_accuracy: 0.3000\n",
      "Epoch 112/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7068 - accuracy: 0.3697 - val_loss: 1.8080 - val_accuracy: 0.3000\n",
      "Epoch 113/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7090 - accuracy: 0.3697 - val_loss: 1.8088 - val_accuracy: 0.3000\n",
      "Epoch 114/2500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.7130 - accuracy: 0.3697 - val_loss: 1.8088 - val_accuracy: 0.3000\n",
      "Epoch 115/2500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.7103 - accuracy: 0.3697 - val_loss: 1.8094 - val_accuracy: 0.3000\n",
      "Epoch 116/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6926 - accuracy: 0.3697 - val_loss: 1.8103 - val_accuracy: 0.3000\n",
      "Epoch 117/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7006 - accuracy: 0.3697 - val_loss: 1.8103 - val_accuracy: 0.3000\n",
      "Epoch 118/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6989 - accuracy: 0.3697 - val_loss: 1.8108 - val_accuracy: 0.3000\n",
      "Epoch 119/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.7078 - accuracy: 0.3697 - val_loss: 1.8106 - val_accuracy: 0.3000\n",
      "Epoch 120/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7088 - accuracy: 0.3697 - val_loss: 1.8104 - val_accuracy: 0.3000\n",
      "Epoch 121/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7022 - accuracy: 0.3697 - val_loss: 1.8108 - val_accuracy: 0.3000\n",
      "Epoch 122/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.7126 - accuracy: 0.3697 - val_loss: 1.8101 - val_accuracy: 0.3000\n",
      "Epoch 123/2500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.7038 - accuracy: 0.3697 - val_loss: 1.8111 - val_accuracy: 0.3000\n",
      "Epoch 124/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.7023 - accuracy: 0.3697 - val_loss: 1.8113 - val_accuracy: 0.3000\n",
      "Epoch 125/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7089 - accuracy: 0.3697 - val_loss: 1.8120 - val_accuracy: 0.3000\n",
      "Epoch 126/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7089 - accuracy: 0.3697 - val_loss: 1.8118 - val_accuracy: 0.3000\n",
      "Epoch 127/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7092 - accuracy: 0.3697 - val_loss: 1.8119 - val_accuracy: 0.3000\n",
      "Epoch 128/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.7046 - accuracy: 0.3697 - val_loss: 1.8122 - val_accuracy: 0.3000\n",
      "Epoch 129/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7081 - accuracy: 0.3697 - val_loss: 1.8120 - val_accuracy: 0.3000\n",
      "Epoch 130/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6759 - accuracy: 0.3697 - val_loss: 1.8127 - val_accuracy: 0.3000\n",
      "Epoch 131/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.7050 - accuracy: 0.3697 - val_loss: 1.8128 - val_accuracy: 0.3000\n",
      "Epoch 132/2500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.6844 - accuracy: 0.3697 - val_loss: 1.8131 - val_accuracy: 0.3000\n",
      "Epoch 133/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6873 - accuracy: 0.3697 - val_loss: 1.8140 - val_accuracy: 0.3000\n",
      "Epoch 134/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7857 - accuracy: 0.26 - 0s 17ms/step - loss: 1.6972 - accuracy: 0.3697 - val_loss: 1.8142 - val_accuracy: 0.3000\n",
      "Epoch 135/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6964 - accuracy: 0.3697 - val_loss: 1.8144 - val_accuracy: 0.3000\n",
      "Epoch 136/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.7149 - accuracy: 0.3697 - val_loss: 1.8140 - val_accuracy: 0.3000\n",
      "Epoch 137/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.6964 - accuracy: 0.3697 - val_loss: 1.8139 - val_accuracy: 0.3000\n",
      "Epoch 138/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6957 - accuracy: 0.3697 - val_loss: 1.8140 - val_accuracy: 0.3000\n",
      "Epoch 139/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6808 - accuracy: 0.3697 - val_loss: 1.8149 - val_accuracy: 0.3000\n",
      "Epoch 140/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6957 - accuracy: 0.3697 - val_loss: 1.8145 - val_accuracy: 0.3000\n",
      "Epoch 141/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6857 - accuracy: 0.3697 - val_loss: 1.8149 - val_accuracy: 0.3000\n",
      "Epoch 142/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7165 - accuracy: 0.3697 - val_loss: 1.8143 - val_accuracy: 0.3000\n",
      "Epoch 143/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6946 - accuracy: 0.3697 - val_loss: 1.8140 - val_accuracy: 0.3000\n",
      "Epoch 144/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.7079 - accuracy: 0.3697 - val_loss: 1.8138 - val_accuracy: 0.3000\n",
      "Epoch 145/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7060 - accuracy: 0.3697 - val_loss: 1.8132 - val_accuracy: 0.3000\n",
      "Epoch 146/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6889 - accuracy: 0.3697 - val_loss: 1.8137 - val_accuracy: 0.3000\n",
      "Epoch 147/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.7092 - accuracy: 0.3697 - val_loss: 1.8133 - val_accuracy: 0.3000\n",
      "Epoch 148/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7102 - accuracy: 0.3697 - val_loss: 1.8136 - val_accuracy: 0.3000\n",
      "Epoch 149/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6869 - accuracy: 0.3697 - val_loss: 1.8145 - val_accuracy: 0.3000\n",
      "Epoch 150/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6906 - accuracy: 0.3697 - val_loss: 1.8149 - val_accuracy: 0.3000\n",
      "Epoch 151/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6923 - accuracy: 0.3697 - val_loss: 1.8142 - val_accuracy: 0.3000\n",
      "Epoch 152/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6898 - accuracy: 0.3697 - val_loss: 1.8140 - val_accuracy: 0.3000\n",
      "Epoch 153/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6732 - accuracy: 0.3697 - val_loss: 1.8149 - val_accuracy: 0.3000\n",
      "Epoch 154/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6892 - accuracy: 0.3697 - val_loss: 1.8157 - val_accuracy: 0.3000\n",
      "Epoch 155/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6898 - accuracy: 0.3697 - val_loss: 1.8148 - val_accuracy: 0.3000\n",
      "Epoch 156/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6860 - accuracy: 0.3697 - val_loss: 1.8151 - val_accuracy: 0.3000\n",
      "Epoch 157/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.7051 - accuracy: 0.3697 - val_loss: 1.8141 - val_accuracy: 0.3000\n",
      "Epoch 158/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6839 - accuracy: 0.3697 - val_loss: 1.8148 - val_accuracy: 0.3000\n",
      "Epoch 159/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6990 - accuracy: 0.3697 - val_loss: 1.8144 - val_accuracy: 0.3000\n",
      "Epoch 160/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6726 - accuracy: 0.3697 - val_loss: 1.8149 - val_accuracy: 0.3000\n",
      "Epoch 161/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6892 - accuracy: 0.3697 - val_loss: 1.8147 - val_accuracy: 0.3000\n",
      "Epoch 162/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6977 - accuracy: 0.3697 - val_loss: 1.8135 - val_accuracy: 0.3000\n",
      "Epoch 163/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6794 - accuracy: 0.3697 - val_loss: 1.8138 - val_accuracy: 0.3000\n",
      "Epoch 164/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6926 - accuracy: 0.3697 - val_loss: 1.8134 - val_accuracy: 0.3000\n",
      "Epoch 165/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7077 - accuracy: 0.3697 - val_loss: 1.8131 - val_accuracy: 0.3000\n",
      "Epoch 166/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6873 - accuracy: 0.3697 - val_loss: 1.8125 - val_accuracy: 0.3000\n",
      "Epoch 167/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.7039 - accuracy: 0.3697 - val_loss: 1.8127 - val_accuracy: 0.3000\n",
      "Epoch 168/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6977 - accuracy: 0.3697 - val_loss: 1.8127 - val_accuracy: 0.3000\n",
      "Epoch 169/2500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.6786 - accuracy: 0.3697 - val_loss: 1.8136 - val_accuracy: 0.3000\n",
      "Epoch 170/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6915 - accuracy: 0.3697 - val_loss: 1.8136 - val_accuracy: 0.3000\n",
      "Epoch 171/2500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.6771 - accuracy: 0.3697 - val_loss: 1.8141 - val_accuracy: 0.3000\n",
      "Epoch 172/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6685 - accuracy: 0.3697 - val_loss: 1.8147 - val_accuracy: 0.3000\n",
      "Epoch 173/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6804 - accuracy: 0.3697 - val_loss: 1.8155 - val_accuracy: 0.3000\n",
      "Epoch 174/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6937 - accuracy: 0.3697 - val_loss: 1.8150 - val_accuracy: 0.3000\n",
      "Epoch 175/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6917 - accuracy: 0.3697 - val_loss: 1.8153 - val_accuracy: 0.3000\n",
      "Epoch 176/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6851 - accuracy: 0.3697 - val_loss: 1.8155 - val_accuracy: 0.3000\n",
      "Epoch 177/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6915 - accuracy: 0.3697 - val_loss: 1.8154 - val_accuracy: 0.3000\n",
      "Epoch 178/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6858 - accuracy: 0.3697 - val_loss: 1.8151 - val_accuracy: 0.3000\n",
      "Epoch 179/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6913 - accuracy: 0.3697 - val_loss: 1.8143 - val_accuracy: 0.3000\n",
      "Epoch 180/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6720 - accuracy: 0.3697 - val_loss: 1.8152 - val_accuracy: 0.3000\n",
      "Epoch 181/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6831 - accuracy: 0.3697 - val_loss: 1.8150 - val_accuracy: 0.3000\n",
      "Epoch 182/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6618 - accuracy: 0.3697 - val_loss: 1.8155 - val_accuracy: 0.3000\n",
      "Epoch 183/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6846 - accuracy: 0.3697 - val_loss: 1.8151 - val_accuracy: 0.3000\n",
      "Epoch 184/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6689 - accuracy: 0.3697 - val_loss: 1.8156 - val_accuracy: 0.3000\n",
      "Epoch 185/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6918 - accuracy: 0.3697 - val_loss: 1.8144 - val_accuracy: 0.3000\n",
      "Epoch 186/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6868 - accuracy: 0.34 - 0s 16ms/step - loss: 1.6820 - accuracy: 0.3697 - val_loss: 1.8149 - val_accuracy: 0.3000\n",
      "Epoch 187/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6898 - accuracy: 0.3697 - val_loss: 1.8137 - val_accuracy: 0.3000\n",
      "Epoch 188/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6976 - accuracy: 0.3697 - val_loss: 1.8128 - val_accuracy: 0.3000\n",
      "Epoch 189/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6775 - accuracy: 0.3697 - val_loss: 1.8132 - val_accuracy: 0.3000\n",
      "Epoch 190/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6163 - accuracy: 0.37 - 0s 18ms/step - loss: 1.6701 - accuracy: 0.3697 - val_loss: 1.8132 - val_accuracy: 0.3000\n",
      "Epoch 191/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.6741 - accuracy: 0.3697 - val_loss: 1.8135 - val_accuracy: 0.3000\n",
      "Epoch 192/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6771 - accuracy: 0.3697 - val_loss: 1.8131 - val_accuracy: 0.3000\n",
      "Epoch 193/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6772 - accuracy: 0.3697 - val_loss: 1.8126 - val_accuracy: 0.3000\n",
      "Epoch 194/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6851 - accuracy: 0.3697 - val_loss: 1.8120 - val_accuracy: 0.3000\n",
      "Epoch 195/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6848 - accuracy: 0.3697 - val_loss: 1.8107 - val_accuracy: 0.3000\n",
      "Epoch 196/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6667 - accuracy: 0.3697 - val_loss: 1.8110 - val_accuracy: 0.3000\n",
      "Epoch 197/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6652 - accuracy: 0.3697 - val_loss: 1.8107 - val_accuracy: 0.3000\n",
      "Epoch 198/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6715 - accuracy: 0.3697 - val_loss: 1.8101 - val_accuracy: 0.3000\n",
      "Epoch 199/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.6667 - accuracy: 0.3697 - val_loss: 1.8098 - val_accuracy: 0.3000\n",
      "Epoch 200/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.6878 - accuracy: 0.3697 - val_loss: 1.8088 - val_accuracy: 0.3000\n",
      "Epoch 201/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6833 - accuracy: 0.3697 - val_loss: 1.8080 - val_accuracy: 0.3000\n",
      "Epoch 202/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.6742 - accuracy: 0.3697 - val_loss: 1.8074 - val_accuracy: 0.3000\n",
      "Epoch 203/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6546 - accuracy: 0.3697 - val_loss: 1.8086 - val_accuracy: 0.3000\n",
      "Epoch 204/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6702 - accuracy: 0.3697 - val_loss: 1.8080 - val_accuracy: 0.3000\n",
      "Epoch 205/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6807 - accuracy: 0.3697 - val_loss: 1.8070 - val_accuracy: 0.3000\n",
      "Epoch 206/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6503 - accuracy: 0.3697 - val_loss: 1.8076 - val_accuracy: 0.3000\n",
      "Epoch 207/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6889 - accuracy: 0.3697 - val_loss: 1.8056 - val_accuracy: 0.3000\n",
      "Epoch 208/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6731 - accuracy: 0.3697 - val_loss: 1.8046 - val_accuracy: 0.3000\n",
      "Epoch 209/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6905 - accuracy: 0.3697 - val_loss: 1.8032 - val_accuracy: 0.3000\n",
      "Epoch 210/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.6878 - accuracy: 0.3697 - val_loss: 1.8030 - val_accuracy: 0.3000\n",
      "Epoch 211/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6726 - accuracy: 0.3697 - val_loss: 1.8033 - val_accuracy: 0.3000\n",
      "Epoch 212/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6628 - accuracy: 0.3697 - val_loss: 1.8025 - val_accuracy: 0.3000\n",
      "Epoch 213/2500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6750 - accuracy: 0.3697 - val_loss: 1.8027 - val_accuracy: 0.3000\n",
      "Epoch 214/2500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6569 - accuracy: 0.3697 - val_loss: 1.8036 - val_accuracy: 0.3000\n",
      "Epoch 215/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6766 - accuracy: 0.3697 - val_loss: 1.8039 - val_accuracy: 0.3000\n",
      "Epoch 216/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6826 - accuracy: 0.3697 - val_loss: 1.8032 - val_accuracy: 0.3000\n",
      "Epoch 217/2500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.6775 - accuracy: 0.3697 - val_loss: 1.8028 - val_accuracy: 0.3000\n",
      "Epoch 218/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6693 - accuracy: 0.3697 - val_loss: 1.8023 - val_accuracy: 0.3000\n",
      "Epoch 219/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6695 - accuracy: 0.3697 - val_loss: 1.8013 - val_accuracy: 0.3000\n",
      "Epoch 220/2500\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.6682 - accuracy: 0.3697 - val_loss: 1.8005 - val_accuracy: 0.3000\n",
      "Epoch 221/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6444 - accuracy: 0.3697 - val_loss: 1.8009 - val_accuracy: 0.3000\n",
      "Epoch 222/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6601 - accuracy: 0.3697 - val_loss: 1.8013 - val_accuracy: 0.3000\n",
      "Epoch 223/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6709 - accuracy: 0.3697 - val_loss: 1.8008 - val_accuracy: 0.3000\n",
      "Epoch 224/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6628 - accuracy: 0.3697 - val_loss: 1.8007 - val_accuracy: 0.3000\n",
      "Epoch 225/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6626 - accuracy: 0.3697 - val_loss: 1.7994 - val_accuracy: 0.3000\n",
      "Epoch 226/2500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.6654 - accuracy: 0.3697 - val_loss: 1.7980 - val_accuracy: 0.3000\n",
      "Epoch 227/2500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.6885 - accuracy: 0.3697 - val_loss: 1.7964 - val_accuracy: 0.3000\n",
      "Epoch 228/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6609 - accuracy: 0.3697 - val_loss: 1.7969 - val_accuracy: 0.3000\n",
      "Epoch 229/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6589 - accuracy: 0.3697 - val_loss: 1.7966 - val_accuracy: 0.3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6752 - accuracy: 0.3697 - val_loss: 1.7957 - val_accuracy: 0.3000\n",
      "Epoch 231/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6550 - accuracy: 0.3697 - val_loss: 1.7952 - val_accuracy: 0.3000\n",
      "Epoch 232/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6662 - accuracy: 0.3697 - val_loss: 1.7940 - val_accuracy: 0.3000\n",
      "Epoch 233/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6719 - accuracy: 0.3697 - val_loss: 1.7934 - val_accuracy: 0.3000\n",
      "Epoch 234/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6701 - accuracy: 0.3697 - val_loss: 1.7932 - val_accuracy: 0.3000\n",
      "Epoch 235/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6559 - accuracy: 0.3697 - val_loss: 1.7930 - val_accuracy: 0.3000\n",
      "Epoch 236/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6602 - accuracy: 0.3697 - val_loss: 1.7925 - val_accuracy: 0.3000\n",
      "Epoch 237/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6682 - accuracy: 0.3697 - val_loss: 1.7919 - val_accuracy: 0.3000\n",
      "Epoch 238/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6505 - accuracy: 0.3697 - val_loss: 1.7911 - val_accuracy: 0.3000\n",
      "Epoch 239/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6542 - accuracy: 0.3697 - val_loss: 1.7903 - val_accuracy: 0.3000\n",
      "Epoch 240/2500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.6392 - accuracy: 0.3697 - val_loss: 1.7900 - val_accuracy: 0.3000\n",
      "Epoch 241/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6652 - accuracy: 0.3697 - val_loss: 1.7893 - val_accuracy: 0.3000\n",
      "Epoch 242/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6451 - accuracy: 0.3697 - val_loss: 1.7890 - val_accuracy: 0.3000\n",
      "Epoch 243/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6330 - accuracy: 0.3697 - val_loss: 1.7896 - val_accuracy: 0.3000\n",
      "Epoch 244/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6815 - accuracy: 0.3697 - val_loss: 1.7872 - val_accuracy: 0.3000\n",
      "Epoch 245/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6564 - accuracy: 0.3697 - val_loss: 1.7868 - val_accuracy: 0.3000\n",
      "Epoch 246/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6424 - accuracy: 0.3697 - val_loss: 1.7865 - val_accuracy: 0.3000\n",
      "Epoch 247/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6452 - accuracy: 0.3697 - val_loss: 1.7872 - val_accuracy: 0.3000\n",
      "Epoch 248/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6530 - accuracy: 0.3697 - val_loss: 1.7867 - val_accuracy: 0.3000\n",
      "Epoch 249/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6469 - accuracy: 0.3697 - val_loss: 1.7860 - val_accuracy: 0.3000\n",
      "Epoch 250/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6243 - accuracy: 0.3697 - val_loss: 1.7874 - val_accuracy: 0.3000\n",
      "Epoch 251/2500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.6367 - accuracy: 0.3697 - val_loss: 1.7869 - val_accuracy: 0.3000\n",
      "Epoch 252/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6251 - accuracy: 0.3697 - val_loss: 1.7864 - val_accuracy: 0.3000\n",
      "Epoch 253/2500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.6332 - accuracy: 0.3697 - val_loss: 1.7853 - val_accuracy: 0.3000\n",
      "Epoch 254/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6226 - accuracy: 0.3697 - val_loss: 1.7845 - val_accuracy: 0.3000\n",
      "Epoch 255/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6303 - accuracy: 0.3697 - val_loss: 1.7838 - val_accuracy: 0.3000\n",
      "Epoch 256/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6592 - accuracy: 0.3697 - val_loss: 1.7829 - val_accuracy: 0.3000\n",
      "Epoch 257/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6369 - accuracy: 0.3697 - val_loss: 1.7827 - val_accuracy: 0.3000\n",
      "Epoch 258/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6658 - accuracy: 0.3697 - val_loss: 1.7807 - val_accuracy: 0.3000\n",
      "Epoch 259/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6441 - accuracy: 0.3697 - val_loss: 1.7784 - val_accuracy: 0.3000\n",
      "Epoch 260/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6203 - accuracy: 0.3697 - val_loss: 1.7782 - val_accuracy: 0.3000\n",
      "Epoch 261/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6392 - accuracy: 0.3697 - val_loss: 1.7756 - val_accuracy: 0.3000\n",
      "Epoch 262/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6226 - accuracy: 0.3697 - val_loss: 1.7747 - val_accuracy: 0.3000\n",
      "Epoch 263/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6346 - accuracy: 0.3697 - val_loss: 1.7738 - val_accuracy: 0.3000\n",
      "Epoch 264/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6362 - accuracy: 0.3697 - val_loss: 1.7715 - val_accuracy: 0.3000\n",
      "Epoch 265/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6493 - accuracy: 0.3697 - val_loss: 1.7696 - val_accuracy: 0.3000\n",
      "Epoch 266/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6114 - accuracy: 0.3697 - val_loss: 1.7688 - val_accuracy: 0.3000\n",
      "Epoch 267/2500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.6292 - accuracy: 0.3697 - val_loss: 1.7677 - val_accuracy: 0.3000\n",
      "Epoch 268/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6532 - accuracy: 0.3697 - val_loss: 1.7650 - val_accuracy: 0.3000\n",
      "Epoch 269/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6119 - accuracy: 0.3697 - val_loss: 1.7658 - val_accuracy: 0.3000\n",
      "Epoch 270/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6153 - accuracy: 0.3697 - val_loss: 1.7647 - val_accuracy: 0.3000\n",
      "Epoch 271/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5935 - accuracy: 0.3697 - val_loss: 1.7653 - val_accuracy: 0.3000\n",
      "Epoch 272/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6427 - accuracy: 0.3697 - val_loss: 1.7635 - val_accuracy: 0.3000\n",
      "Epoch 273/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6032 - accuracy: 0.3697 - val_loss: 1.7635 - val_accuracy: 0.3000\n",
      "Epoch 274/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5940 - accuracy: 0.3697 - val_loss: 1.7585 - val_accuracy: 0.3000\n",
      "Epoch 275/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6240 - accuracy: 0.3697 - val_loss: 1.7587 - val_accuracy: 0.3000\n",
      "Epoch 276/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6287 - accuracy: 0.3697 - val_loss: 1.7560 - val_accuracy: 0.3000\n",
      "Epoch 277/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6199 - accuracy: 0.3697 - val_loss: 1.7596 - val_accuracy: 0.3000\n",
      "Epoch 278/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6040 - accuracy: 0.3697 - val_loss: 1.7585 - val_accuracy: 0.3000\n",
      "Epoch 279/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6179 - accuracy: 0.3697 - val_loss: 1.7574 - val_accuracy: 0.3000\n",
      "Epoch 280/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6156 - accuracy: 0.3697 - val_loss: 1.7545 - val_accuracy: 0.3000\n",
      "Epoch 281/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.6253 - accuracy: 0.3697 - val_loss: 1.7526 - val_accuracy: 0.3000\n",
      "Epoch 282/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6297 - accuracy: 0.3697 - val_loss: 1.7500 - val_accuracy: 0.3000\n",
      "Epoch 283/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5857 - accuracy: 0.3697 - val_loss: 1.7500 - val_accuracy: 0.3000\n",
      "Epoch 284/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5770 - accuracy: 0.3697 - val_loss: 1.7491 - val_accuracy: 0.3000\n",
      "Epoch 285/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5877 - accuracy: 0.3697 - val_loss: 1.7489 - val_accuracy: 0.3000\n",
      "Epoch 286/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6081 - accuracy: 0.3697 - val_loss: 1.7479 - val_accuracy: 0.3000\n",
      "Epoch 287/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5992 - accuracy: 0.3697 - val_loss: 1.7472 - val_accuracy: 0.3000\n",
      "Epoch 288/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.5918 - accuracy: 0.3697 - val_loss: 1.7458 - val_accuracy: 0.3000\n",
      "Epoch 289/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6093 - accuracy: 0.3697 - val_loss: 1.7434 - val_accuracy: 0.3000\n",
      "Epoch 290/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.5783 - accuracy: 0.3697 - val_loss: 1.7056 - val_accuracy: 0.3000\n",
      "Epoch 291/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5624 - accuracy: 0.3697 - val_loss: 1.7039 - val_accuracy: 0.3000\n",
      "Epoch 292/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5978 - accuracy: 0.3697 - val_loss: 1.7028 - val_accuracy: 0.3000\n",
      "Epoch 293/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.5904 - accuracy: 0.3697 - val_loss: 1.7008 - val_accuracy: 0.3000\n",
      "Epoch 294/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5886 - accuracy: 0.3697 - val_loss: 1.6979 - val_accuracy: 0.3000\n",
      "Epoch 295/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.5409 - accuracy: 0.3697 - val_loss: 1.6978 - val_accuracy: 0.3000\n",
      "Epoch 296/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.5881 - accuracy: 0.3697 - val_loss: 1.6961 - val_accuracy: 0.3000\n",
      "Epoch 297/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5633 - accuracy: 0.3697 - val_loss: 1.6947 - val_accuracy: 0.3000\n",
      "Epoch 298/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.5849 - accuracy: 0.3697 - val_loss: 1.6925 - val_accuracy: 0.3000\n",
      "Epoch 299/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5583 - accuracy: 0.3697 - val_loss: 1.6908 - val_accuracy: 0.3000\n",
      "Epoch 300/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.6045 - accuracy: 0.3697 - val_loss: 1.6872 - val_accuracy: 0.3000\n",
      "Epoch 301/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.5779 - accuracy: 0.3697 - val_loss: 1.6845 - val_accuracy: 0.3000\n",
      "Epoch 302/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5921 - accuracy: 0.3697 - val_loss: 1.6821 - val_accuracy: 0.3000\n",
      "Epoch 303/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5742 - accuracy: 0.3697 - val_loss: 1.6806 - val_accuracy: 0.3000\n",
      "Epoch 304/2500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.5719 - accuracy: 0.3697 - val_loss: 1.6794 - val_accuracy: 0.3000\n",
      "Epoch 305/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.5476 - accuracy: 0.3697 - val_loss: 1.6783 - val_accuracy: 0.3000\n",
      "Epoch 306/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5843 - accuracy: 0.3697 - val_loss: 1.6759 - val_accuracy: 0.3000\n",
      "Epoch 307/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.5667 - accuracy: 0.3697 - val_loss: 1.6721 - val_accuracy: 0.3000\n",
      "Epoch 308/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5517 - accuracy: 0.3697 - val_loss: 1.6692 - val_accuracy: 0.3000\n",
      "Epoch 309/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.5779 - accuracy: 0.3697 - val_loss: 1.6668 - val_accuracy: 0.3000\n",
      "Epoch 310/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.5392 - accuracy: 0.3697 - val_loss: 1.6652 - val_accuracy: 0.3000\n",
      "Epoch 311/2500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.5566 - accuracy: 0.3697 - val_loss: 1.6629 - val_accuracy: 0.3000\n",
      "Epoch 312/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5497 - accuracy: 0.3697 - val_loss: 1.6608 - val_accuracy: 0.3000\n",
      "Epoch 313/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5459 - accuracy: 0.3697 - val_loss: 1.6590 - val_accuracy: 0.3000\n",
      "Epoch 314/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.5293 - accuracy: 0.3697 - val_loss: 1.6575 - val_accuracy: 0.3000\n",
      "Epoch 315/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5365 - accuracy: 0.3697 - val_loss: 1.6543 - val_accuracy: 0.3000\n",
      "Epoch 316/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5889 - accuracy: 0.3697 - val_loss: 1.6520 - val_accuracy: 0.3000\n",
      "Epoch 317/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.5694 - accuracy: 0.3697 - val_loss: 1.6506 - val_accuracy: 0.3000\n",
      "Epoch 318/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5603 - accuracy: 0.3697 - val_loss: 1.6492 - val_accuracy: 0.3000\n",
      "Epoch 319/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5552 - accuracy: 0.3697 - val_loss: 1.6467 - val_accuracy: 0.3000\n",
      "Epoch 320/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5879 - accuracy: 0.3697 - val_loss: 1.6321 - val_accuracy: 0.3000\n",
      "Epoch 321/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5423 - accuracy: 0.3697 - val_loss: 1.6306 - val_accuracy: 0.3000\n",
      "Epoch 322/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5863 - accuracy: 0.3697 - val_loss: 1.6295 - val_accuracy: 0.3000\n",
      "Epoch 323/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5933 - accuracy: 0.3697 - val_loss: 1.6272 - val_accuracy: 0.3000\n",
      "Epoch 324/2500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.5880 - accuracy: 0.3697 - val_loss: 1.6260 - val_accuracy: 0.3000\n",
      "Epoch 325/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5347 - accuracy: 0.3697 - val_loss: 1.6265 - val_accuracy: 0.3000\n",
      "Epoch 326/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5297 - accuracy: 0.3697 - val_loss: 1.6258 - val_accuracy: 0.3000\n",
      "Epoch 327/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5004 - accuracy: 0.3697 - val_loss: 1.6258 - val_accuracy: 0.3000\n",
      "Epoch 328/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5472 - accuracy: 0.3697 - val_loss: 1.6247 - val_accuracy: 0.3000\n",
      "Epoch 329/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.4921 - accuracy: 0.3697 - val_loss: 1.6253 - val_accuracy: 0.3000\n",
      "Epoch 330/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.5595 - accuracy: 0.3697 - val_loss: 1.6253 - val_accuracy: 0.3000\n",
      "Epoch 331/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5710 - accuracy: 0.3697 - val_loss: 1.6243 - val_accuracy: 0.3000\n",
      "Epoch 332/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5379 - accuracy: 0.3697 - val_loss: 1.6246 - val_accuracy: 0.3000\n",
      "Epoch 333/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5399 - accuracy: 0.3697 - val_loss: 1.6252 - val_accuracy: 0.3000\n",
      "Epoch 334/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5391 - accuracy: 0.3697 - val_loss: 1.6260 - val_accuracy: 0.3000\n",
      "Epoch 335/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5446 - accuracy: 0.3697 - val_loss: 1.6254 - val_accuracy: 0.3000\n",
      "Epoch 336/2500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.5246 - accuracy: 0.3697 - val_loss: 1.6261 - val_accuracy: 0.3000\n",
      "Epoch 337/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5480 - accuracy: 0.3697 - val_loss: 1.6263 - val_accuracy: 0.3000\n",
      "Epoch 338/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5774 - accuracy: 0.3697 - val_loss: 1.6243 - val_accuracy: 0.3000\n",
      "Epoch 339/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4809 - accuracy: 0.3697 - val_loss: 1.6241 - val_accuracy: 0.3000\n",
      "Epoch 340/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5265 - accuracy: 0.3697 - val_loss: 1.6408 - val_accuracy: 0.3000\n",
      "Epoch 341/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5593 - accuracy: 0.3697 - val_loss: 1.6385 - val_accuracy: 0.3000\n",
      "Epoch 342/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.6054 - accuracy: 0.3697 - val_loss: 1.6361 - val_accuracy: 0.3000\n",
      "Epoch 343/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5048 - accuracy: 0.3697 - val_loss: 1.6391 - val_accuracy: 0.3000\n",
      "Epoch 344/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5006 - accuracy: 0.3697 - val_loss: 1.6394 - val_accuracy: 0.3000\n",
      "Epoch 345/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6078 - accuracy: 0.37 - 0s 11ms/step - loss: 1.6043 - accuracy: 0.3697 - val_loss: 1.6345 - val_accuracy: 0.3000\n",
      "Epoch 346/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5192 - accuracy: 0.3697 - val_loss: 1.6360 - val_accuracy: 0.3000\n",
      "Epoch 347/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5447 - accuracy: 0.3697 - val_loss: 1.6374 - val_accuracy: 0.3000\n",
      "Epoch 348/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5459 - accuracy: 0.3697 - val_loss: 1.6366 - val_accuracy: 0.3000\n",
      "Epoch 349/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4856 - accuracy: 0.3697 - val_loss: 1.6381 - val_accuracy: 0.3000\n",
      "Epoch 350/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5221 - accuracy: 0.3697 - val_loss: 1.6382 - val_accuracy: 0.3000\n",
      "Epoch 351/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5358 - accuracy: 0.3697 - val_loss: 1.6383 - val_accuracy: 0.3000\n",
      "Epoch 352/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5576 - accuracy: 0.3697 - val_loss: 1.6368 - val_accuracy: 0.3000\n",
      "Epoch 353/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5558 - accuracy: 0.3697 - val_loss: 1.6346 - val_accuracy: 0.3000\n",
      "Epoch 354/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5265 - accuracy: 0.3697 - val_loss: 1.6347 - val_accuracy: 0.3000\n",
      "Epoch 355/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5584 - accuracy: 0.3697 - val_loss: 1.6342 - val_accuracy: 0.3000\n",
      "Epoch 356/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5686 - accuracy: 0.3697 - val_loss: 1.6340 - val_accuracy: 0.3000\n",
      "Epoch 357/2500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.5005 - accuracy: 0.3697 - val_loss: 1.6351 - val_accuracy: 0.3000\n",
      "Epoch 358/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5790 - accuracy: 0.3697 - val_loss: 1.6328 - val_accuracy: 0.3000\n",
      "Epoch 359/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4863 - accuracy: 0.3697 - val_loss: 1.6326 - val_accuracy: 0.3000\n",
      "Epoch 360/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5258 - accuracy: 0.3697 - val_loss: 1.6325 - val_accuracy: 0.3000\n",
      "Epoch 361/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5101 - accuracy: 0.3697 - val_loss: 1.6330 - val_accuracy: 0.3000\n",
      "Epoch 362/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5061 - accuracy: 0.3697 - val_loss: 1.6352 - val_accuracy: 0.3000\n",
      "Epoch 363/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5739 - accuracy: 0.3697 - val_loss: 1.6336 - val_accuracy: 0.3000\n",
      "Epoch 364/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5530 - accuracy: 0.3697 - val_loss: 1.6338 - val_accuracy: 0.3000\n",
      "Epoch 365/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5422 - accuracy: 0.3697 - val_loss: 1.6329 - val_accuracy: 0.3000\n",
      "Epoch 366/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4577 - accuracy: 0.3697 - val_loss: 1.6343 - val_accuracy: 0.3000\n",
      "Epoch 367/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4881 - accuracy: 0.3697 - val_loss: 1.6330 - val_accuracy: 0.3000\n",
      "Epoch 368/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5088 - accuracy: 0.3697 - val_loss: 1.6328 - val_accuracy: 0.3000\n",
      "Epoch 369/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5065 - accuracy: 0.3697 - val_loss: 1.6342 - val_accuracy: 0.3000\n",
      "Epoch 370/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4978 - accuracy: 0.3697 - val_loss: 1.6343 - val_accuracy: 0.3000\n",
      "Epoch 371/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4609 - accuracy: 0.3697 - val_loss: 1.6347 - val_accuracy: 0.3000\n",
      "Epoch 372/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5561 - accuracy: 0.3697 - val_loss: 1.6321 - val_accuracy: 0.3000\n",
      "Epoch 373/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5664 - accuracy: 0.3697 - val_loss: 1.6321 - val_accuracy: 0.3000\n",
      "Epoch 374/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.6074 - accuracy: 0.3697 - val_loss: 1.6277 - val_accuracy: 0.3000\n",
      "Epoch 375/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5424 - accuracy: 0.3697 - val_loss: 1.6266 - val_accuracy: 0.3000\n",
      "Epoch 376/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4980 - accuracy: 0.3697 - val_loss: 1.6252 - val_accuracy: 0.3000\n",
      "Epoch 377/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.4457 - accuracy: 0.3697 - val_loss: 1.6258 - val_accuracy: 0.3000\n",
      "Epoch 378/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4667 - accuracy: 0.3697 - val_loss: 1.6284 - val_accuracy: 0.3000\n",
      "Epoch 379/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4768 - accuracy: 0.3697 - val_loss: 1.6279 - val_accuracy: 0.3000\n",
      "Epoch 380/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5356 - accuracy: 0.3697 - val_loss: 1.6274 - val_accuracy: 0.3000\n",
      "Epoch 381/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5252 - accuracy: 0.3697 - val_loss: 1.6276 - val_accuracy: 0.3000\n",
      "Epoch 382/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4985 - accuracy: 0.3697 - val_loss: 1.6253 - val_accuracy: 0.3000\n",
      "Epoch 383/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5102 - accuracy: 0.3782 - val_loss: 1.6240 - val_accuracy: 0.3000\n",
      "Epoch 384/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5560 - accuracy: 0.3697 - val_loss: 1.6215 - val_accuracy: 0.3000\n",
      "Epoch 385/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5643 - accuracy: 0.3697 - val_loss: 1.6204 - val_accuracy: 0.3000\n",
      "Epoch 386/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5683 - accuracy: 0.3866 - val_loss: 1.6177 - val_accuracy: 0.3000\n",
      "Epoch 387/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5201 - accuracy: 0.4034 - val_loss: 1.6199 - val_accuracy: 0.3000\n",
      "Epoch 388/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5551 - accuracy: 0.3613 - val_loss: 1.6180 - val_accuracy: 0.3000\n",
      "Epoch 389/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5390 - accuracy: 0.3950 - val_loss: 1.6184 - val_accuracy: 0.3000\n",
      "Epoch 390/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5639 - accuracy: 0.4202 - val_loss: 1.6172 - val_accuracy: 0.3000\n",
      "Epoch 391/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5127 - accuracy: 0.4202 - val_loss: 1.6204 - val_accuracy: 0.3000\n",
      "Epoch 392/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4870 - accuracy: 0.4034 - val_loss: 1.6220 - val_accuracy: 0.3000\n",
      "Epoch 393/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4928 - accuracy: 0.4034 - val_loss: 1.6230 - val_accuracy: 0.3000\n",
      "Epoch 394/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5921 - accuracy: 0.3866 - val_loss: 1.6192 - val_accuracy: 0.3000\n",
      "Epoch 395/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4712 - accuracy: 0.4202 - val_loss: 1.6193 - val_accuracy: 0.3000\n",
      "Epoch 396/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5272 - accuracy: 0.4286 - val_loss: 1.6182 - val_accuracy: 0.3000\n",
      "Epoch 397/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5252 - accuracy: 0.4118 - val_loss: 1.6186 - val_accuracy: 0.3000\n",
      "Epoch 398/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5275 - accuracy: 0.4202 - val_loss: 1.6194 - val_accuracy: 0.3000\n",
      "Epoch 399/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4666 - accuracy: 0.4286 - val_loss: 1.6205 - val_accuracy: 0.3000\n",
      "Epoch 400/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5637 - accuracy: 0.3950 - val_loss: 1.6182 - val_accuracy: 0.3000\n",
      "Epoch 401/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4905 - accuracy: 0.4118 - val_loss: 1.6184 - val_accuracy: 0.3000\n",
      "Epoch 402/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4971 - accuracy: 0.3866 - val_loss: 1.6183 - val_accuracy: 0.3000\n",
      "Epoch 403/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5441 - accuracy: 0.4286 - val_loss: 1.6175 - val_accuracy: 0.3000\n",
      "Epoch 404/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.5434 - accuracy: 0.4370 - val_loss: 1.6177 - val_accuracy: 0.3000\n",
      "Epoch 405/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5288 - accuracy: 0.4118 - val_loss: 1.6150 - val_accuracy: 0.3000\n",
      "Epoch 406/2500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.5080 - accuracy: 0.4286 - val_loss: 1.6152 - val_accuracy: 0.3000\n",
      "Epoch 407/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4992 - accuracy: 0.3866 - val_loss: 1.6155 - val_accuracy: 0.3000\n",
      "Epoch 408/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4681 - accuracy: 0.4034 - val_loss: 1.6155 - val_accuracy: 0.3000\n",
      "Epoch 409/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4788 - accuracy: 0.3950 - val_loss: 1.6177 - val_accuracy: 0.3000\n",
      "Epoch 410/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5617 - accuracy: 0.4370 - val_loss: 1.6148 - val_accuracy: 0.3000\n",
      "Epoch 411/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4761 - accuracy: 0.4034 - val_loss: 1.6155 - val_accuracy: 0.3000\n",
      "Epoch 412/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5168 - accuracy: 0.4034 - val_loss: 1.6146 - val_accuracy: 0.3000\n",
      "Epoch 413/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4371 - accuracy: 0.4370 - val_loss: 1.6191 - val_accuracy: 0.3000\n",
      "Epoch 414/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3534 - accuracy: 0.46 - 0s 11ms/step - loss: 1.4841 - accuracy: 0.3950 - val_loss: 1.6186 - val_accuracy: 0.3000\n",
      "Epoch 415/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4625 - accuracy: 0.4118 - val_loss: 1.6202 - val_accuracy: 0.3000\n",
      "Epoch 416/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5235 - accuracy: 0.3950 - val_loss: 1.6200 - val_accuracy: 0.3000\n",
      "Epoch 417/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5430 - accuracy: 0.4370 - val_loss: 1.6195 - val_accuracy: 0.3000\n",
      "Epoch 418/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5273 - accuracy: 0.4034 - val_loss: 1.6193 - val_accuracy: 0.3000\n",
      "Epoch 419/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4662 - accuracy: 0.4370 - val_loss: 1.6236 - val_accuracy: 0.3000\n",
      "Epoch 420/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4847 - accuracy: 0.4202 - val_loss: 1.6241 - val_accuracy: 0.3000\n",
      "Epoch 421/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4603 - accuracy: 0.4202 - val_loss: 1.6241 - val_accuracy: 0.3000\n",
      "Epoch 422/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5294 - accuracy: 0.4034 - val_loss: 1.6232 - val_accuracy: 0.3000\n",
      "Epoch 423/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4715 - accuracy: 0.3866 - val_loss: 1.6252 - val_accuracy: 0.3000\n",
      "Epoch 424/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5023 - accuracy: 0.4118 - val_loss: 1.6256 - val_accuracy: 0.3000\n",
      "Epoch 425/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4984 - accuracy: 0.4118 - val_loss: 1.6249 - val_accuracy: 0.3000\n",
      "Epoch 426/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4891 - accuracy: 0.4286 - val_loss: 1.6264 - val_accuracy: 0.3000\n",
      "Epoch 427/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4654 - accuracy: 0.4286 - val_loss: 1.6295 - val_accuracy: 0.3000\n",
      "Epoch 428/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4858 - accuracy: 0.4370 - val_loss: 1.6287 - val_accuracy: 0.3000\n",
      "Epoch 429/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5005 - accuracy: 0.4034 - val_loss: 1.6279 - val_accuracy: 0.3000\n",
      "Epoch 430/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4753 - accuracy: 0.4286 - val_loss: 1.6289 - val_accuracy: 0.3000\n",
      "Epoch 431/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4886 - accuracy: 0.4202 - val_loss: 1.6292 - val_accuracy: 0.3000\n",
      "Epoch 432/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4851 - accuracy: 0.4454 - val_loss: 1.6282 - val_accuracy: 0.3000\n",
      "Epoch 433/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4912 - accuracy: 0.4118 - val_loss: 1.6300 - val_accuracy: 0.3000\n",
      "Epoch 434/2500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.5034 - accuracy: 0.4202 - val_loss: 1.6290 - val_accuracy: 0.3000\n",
      "Epoch 435/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4633 - accuracy: 0.4202 - val_loss: 1.6333 - val_accuracy: 0.3000\n",
      "Epoch 436/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5807 - accuracy: 0.3782 - val_loss: 1.6296 - val_accuracy: 0.3000\n",
      "Epoch 437/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5065 - accuracy: 0.4118 - val_loss: 1.6287 - val_accuracy: 0.3000\n",
      "Epoch 438/2500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.6072 - accuracy: 0.3866 - val_loss: 1.6250 - val_accuracy: 0.3000\n",
      "Epoch 439/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5587 - accuracy: 0.4118 - val_loss: 1.6242 - val_accuracy: 0.3000\n",
      "Epoch 440/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5146 - accuracy: 0.4118 - val_loss: 1.6231 - val_accuracy: 0.3000\n",
      "Epoch 441/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4811 - accuracy: 0.4370 - val_loss: 1.6255 - val_accuracy: 0.3000\n",
      "Epoch 442/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5367 - accuracy: 0.3782 - val_loss: 1.6242 - val_accuracy: 0.3000\n",
      "Epoch 443/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4760 - accuracy: 0.4286 - val_loss: 1.6248 - val_accuracy: 0.3000\n",
      "Epoch 444/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5389 - accuracy: 0.4034 - val_loss: 1.6244 - val_accuracy: 0.3000\n",
      "Epoch 445/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5337 - accuracy: 0.4202 - val_loss: 1.6237 - val_accuracy: 0.3000\n",
      "Epoch 446/2500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.4981 - accuracy: 0.4286 - val_loss: 1.6241 - val_accuracy: 0.3000\n",
      "Epoch 447/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5438 - accuracy: 0.4454 - val_loss: 1.6226 - val_accuracy: 0.3000\n",
      "Epoch 448/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5380 - accuracy: 0.4034 - val_loss: 1.6216 - val_accuracy: 0.3000\n",
      "Epoch 449/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4950 - accuracy: 0.3866 - val_loss: 1.6224 - val_accuracy: 0.3000\n",
      "Epoch 450/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4901 - accuracy: 0.3950 - val_loss: 1.6277 - val_accuracy: 0.3000\n",
      "Epoch 451/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4487 - accuracy: 0.4370 - val_loss: 1.6288 - val_accuracy: 0.3000\n",
      "Epoch 452/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5683 - accuracy: 0.3782 - val_loss: 1.6250 - val_accuracy: 0.3000\n",
      "Epoch 453/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5246 - accuracy: 0.3950 - val_loss: 1.6245 - val_accuracy: 0.3000\n",
      "Epoch 454/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5154 - accuracy: 0.4118 - val_loss: 1.6244 - val_accuracy: 0.3000\n",
      "Epoch 455/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4914 - accuracy: 0.4622 - val_loss: 1.6267 - val_accuracy: 0.3000\n",
      "Epoch 456/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4699 - accuracy: 0.4202 - val_loss: 1.6274 - val_accuracy: 0.3000\n",
      "Epoch 457/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5578 - accuracy: 0.3950 - val_loss: 1.6265 - val_accuracy: 0.3000\n",
      "Epoch 458/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4649 - accuracy: 0.4622 - val_loss: 1.6285 - val_accuracy: 0.3000\n",
      "Epoch 459/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4870 - accuracy: 0.4034 - val_loss: 1.6301 - val_accuracy: 0.3000\n",
      "Epoch 460/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5190 - accuracy: 0.4202 - val_loss: 1.6274 - val_accuracy: 0.3000\n",
      "Epoch 461/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5639 - accuracy: 0.4202 - val_loss: 1.6267 - val_accuracy: 0.3000\n",
      "Epoch 462/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5722 - accuracy: 0.4286 - val_loss: 1.6252 - val_accuracy: 0.3000\n",
      "Epoch 463/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5056 - accuracy: 0.4118 - val_loss: 1.6243 - val_accuracy: 0.3000\n",
      "Epoch 464/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4941 - accuracy: 0.3950 - val_loss: 1.6236 - val_accuracy: 0.3000\n",
      "Epoch 465/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5180 - accuracy: 0.4118 - val_loss: 1.6243 - val_accuracy: 0.3000\n",
      "Epoch 466/2500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.5451 - accuracy: 0.4034 - val_loss: 1.6207 - val_accuracy: 0.3000\n",
      "Epoch 467/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5312 - accuracy: 0.4202 - val_loss: 1.6227 - val_accuracy: 0.3000\n",
      "Epoch 468/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4833 - accuracy: 0.3950 - val_loss: 1.6233 - val_accuracy: 0.3000\n",
      "Epoch 469/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5678 - accuracy: 0.4034 - val_loss: 1.6225 - val_accuracy: 0.3000\n",
      "Epoch 470/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5173 - accuracy: 0.4202 - val_loss: 1.6219 - val_accuracy: 0.3000\n",
      "Epoch 471/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4464 - accuracy: 0.4202 - val_loss: 1.6236 - val_accuracy: 0.3000\n",
      "Epoch 472/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4864 - accuracy: 0.4118 - val_loss: 1.6244 - val_accuracy: 0.3000\n",
      "Epoch 473/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5953 - accuracy: 0.3950 - val_loss: 1.6226 - val_accuracy: 0.3000\n",
      "Epoch 474/2500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.5198 - accuracy: 0.4202 - val_loss: 1.6226 - val_accuracy: 0.3000\n",
      "Epoch 475/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5211 - accuracy: 0.4286 - val_loss: 1.6259 - val_accuracy: 0.3000\n",
      "Epoch 476/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5314 - accuracy: 0.4454 - val_loss: 1.6219 - val_accuracy: 0.3000\n",
      "Epoch 477/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4812 - accuracy: 0.4286 - val_loss: 1.6226 - val_accuracy: 0.3000\n",
      "Epoch 478/2500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.4784 - accuracy: 0.3866 - val_loss: 1.6048 - val_accuracy: 0.3250\n",
      "Epoch 479/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5705 - accuracy: 0.3866 - val_loss: 1.6033 - val_accuracy: 0.3250\n",
      "Epoch 480/2500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5183 - accuracy: 0.4118 - val_loss: 1.6015 - val_accuracy: 0.3250\n",
      "Epoch 481/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5010 - accuracy: 0.4202 - val_loss: 1.6021 - val_accuracy: 0.3250\n",
      "Epoch 482/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4446 - accuracy: 0.46 - 0s 16ms/step - loss: 1.4461 - accuracy: 0.4118 - val_loss: 1.5008 - val_accuracy: 0.3500\n",
      "Epoch 483/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5216 - accuracy: 0.4118 - val_loss: 1.5010 - val_accuracy: 0.3500\n",
      "Epoch 484/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4654 - accuracy: 0.4118 - val_loss: 1.5007 - val_accuracy: 0.3500\n",
      "Epoch 485/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5434 - accuracy: 0.4034 - val_loss: 1.6067 - val_accuracy: 0.3250\n",
      "Epoch 486/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5601 - accuracy: 0.3950 - val_loss: 1.6044 - val_accuracy: 0.3250\n",
      "Epoch 487/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5448 - accuracy: 0.4118 - val_loss: 1.6027 - val_accuracy: 0.3250\n",
      "Epoch 488/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5600 - accuracy: 0.3782 - val_loss: 1.6021 - val_accuracy: 0.3250\n",
      "Epoch 489/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5341 - accuracy: 0.3950 - val_loss: 1.6031 - val_accuracy: 0.3250\n",
      "Epoch 490/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4857 - accuracy: 0.3866 - val_loss: 1.6026 - val_accuracy: 0.3250\n",
      "Epoch 491/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5119 - accuracy: 0.4454 - val_loss: 1.6022 - val_accuracy: 0.3250\n",
      "Epoch 492/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5294 - accuracy: 0.4118 - val_loss: 1.6022 - val_accuracy: 0.3250\n",
      "Epoch 493/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5140 - accuracy: 0.4202 - val_loss: 1.6016 - val_accuracy: 0.3250\n",
      "Epoch 494/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5147 - accuracy: 0.4118 - val_loss: 1.6023 - val_accuracy: 0.3250\n",
      "Epoch 495/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4831 - accuracy: 0.4118 - val_loss: 1.6009 - val_accuracy: 0.3250\n",
      "Epoch 496/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5147 - accuracy: 0.4034 - val_loss: 1.5986 - val_accuracy: 0.3250\n",
      "Epoch 497/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5280 - accuracy: 0.4286 - val_loss: 1.5998 - val_accuracy: 0.3250\n",
      "Epoch 498/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4134 - accuracy: 0.46 - 0s 13ms/step - loss: 1.4831 - accuracy: 0.4286 - val_loss: 1.6008 - val_accuracy: 0.3250\n",
      "Epoch 499/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5014 - accuracy: 0.4286 - val_loss: 1.6007 - val_accuracy: 0.3250\n",
      "Epoch 500/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5377 - accuracy: 0.4202 - val_loss: 1.6000 - val_accuracy: 0.3250\n",
      "Epoch 501/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4798 - accuracy: 0.4202 - val_loss: 1.5992 - val_accuracy: 0.3250\n",
      "Epoch 502/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5125 - accuracy: 0.4202 - val_loss: 1.6005 - val_accuracy: 0.3250\n",
      "Epoch 503/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5204 - accuracy: 0.4034 - val_loss: 1.6002 - val_accuracy: 0.3250\n",
      "Epoch 504/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5754 - accuracy: 0.3697 - val_loss: 1.5975 - val_accuracy: 0.3250\n",
      "Epoch 505/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5332 - accuracy: 0.3697 - val_loss: 1.5962 - val_accuracy: 0.3250\n",
      "Epoch 506/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5120 - accuracy: 0.4034 - val_loss: 1.5963 - val_accuracy: 0.3250\n",
      "Epoch 507/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4937 - accuracy: 0.4370 - val_loss: 1.5989 - val_accuracy: 0.3250\n",
      "Epoch 508/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5412 - accuracy: 0.3782 - val_loss: 1.5999 - val_accuracy: 0.3250\n",
      "Epoch 509/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4854 - accuracy: 0.4118 - val_loss: 1.6009 - val_accuracy: 0.3250\n",
      "Epoch 510/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4993 - accuracy: 0.3866 - val_loss: 1.6012 - val_accuracy: 0.3250\n",
      "Epoch 511/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4854 - accuracy: 0.4118 - val_loss: 1.6030 - val_accuracy: 0.3250\n",
      "Epoch 512/2500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.4183 - accuracy: 0.4370 - val_loss: 1.6046 - val_accuracy: 0.3250\n",
      "Epoch 513/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5633 - accuracy: 0.3950 - val_loss: 1.6016 - val_accuracy: 0.3250\n",
      "Epoch 514/2500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.4801 - accuracy: 0.4034 - val_loss: 1.6012 - val_accuracy: 0.3250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 515/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5754 - accuracy: 0.3782 - val_loss: 1.5994 - val_accuracy: 0.3250\n",
      "Epoch 516/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5168 - accuracy: 0.4286 - val_loss: 1.5992 - val_accuracy: 0.3250\n",
      "Epoch 517/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5092 - accuracy: 0.4118 - val_loss: 1.6001 - val_accuracy: 0.3250\n",
      "Epoch 518/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4969 - accuracy: 0.4118 - val_loss: 1.5998 - val_accuracy: 0.3250\n",
      "Epoch 519/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4930 - accuracy: 0.4202 - val_loss: 1.5999 - val_accuracy: 0.3250\n",
      "Epoch 520/2500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.5398 - accuracy: 0.4202 - val_loss: 1.6000 - val_accuracy: 0.3250\n",
      "Epoch 521/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4415 - accuracy: 0.4034 - val_loss: 1.6012 - val_accuracy: 0.3250\n",
      "Epoch 522/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5020 - accuracy: 0.3950 - val_loss: 1.6026 - val_accuracy: 0.3250\n",
      "Epoch 523/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6073 - accuracy: 0.3866 - val_loss: 1.6009 - val_accuracy: 0.3250\n",
      "Epoch 524/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4951 - accuracy: 0.3950 - val_loss: 1.6030 - val_accuracy: 0.3250\n",
      "Epoch 525/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4427 - accuracy: 0.4370 - val_loss: 1.6049 - val_accuracy: 0.3250\n",
      "Epoch 526/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5452 - accuracy: 0.4538 - val_loss: 1.6030 - val_accuracy: 0.3250\n",
      "Epoch 527/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4945 - accuracy: 0.3950 - val_loss: 1.6025 - val_accuracy: 0.3250\n",
      "Epoch 528/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4721 - accuracy: 0.3866 - val_loss: 1.6042 - val_accuracy: 0.3250\n",
      "Epoch 529/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5578 - accuracy: 0.4286 - val_loss: 1.6014 - val_accuracy: 0.3250\n",
      "Epoch 530/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4404 - accuracy: 0.4118 - val_loss: 1.6005 - val_accuracy: 0.3250\n",
      "Epoch 531/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4529 - accuracy: 0.4034 - val_loss: 1.5794 - val_accuracy: 0.3500\n",
      "Epoch 532/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5028 - accuracy: 0.4118 - val_loss: 1.5802 - val_accuracy: 0.3500\n",
      "Epoch 533/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5686 - accuracy: 0.3950 - val_loss: 1.5810 - val_accuracy: 0.3500\n",
      "Epoch 534/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5524 - accuracy: 0.4202 - val_loss: 1.5786 - val_accuracy: 0.3500\n",
      "Epoch 535/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5195 - accuracy: 0.4118 - val_loss: 1.5787 - val_accuracy: 0.3500\n",
      "Epoch 536/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4476 - accuracy: 0.4370 - val_loss: 1.5790 - val_accuracy: 0.3500\n",
      "Epoch 537/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4884 - accuracy: 0.4286 - val_loss: 1.5797 - val_accuracy: 0.3500\n",
      "Epoch 538/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4994 - accuracy: 0.4034 - val_loss: 1.5791 - val_accuracy: 0.3500\n",
      "Epoch 539/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4926 - accuracy: 0.4118 - val_loss: 1.6021 - val_accuracy: 0.3250\n",
      "Epoch 540/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5407 - accuracy: 0.3950 - val_loss: 1.6010 - val_accuracy: 0.3250\n",
      "Epoch 541/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4437 - accuracy: 0.4370 - val_loss: 1.6032 - val_accuracy: 0.3250\n",
      "Epoch 542/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4918 - accuracy: 0.4286 - val_loss: 1.6028 - val_accuracy: 0.3250\n",
      "Epoch 543/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4925 - accuracy: 0.3950 - val_loss: 1.6031 - val_accuracy: 0.3250\n",
      "Epoch 544/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.4774 - accuracy: 0.4202 - val_loss: 1.6015 - val_accuracy: 0.3250\n",
      "Epoch 545/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5818 - accuracy: 0.4202 - val_loss: 1.6008 - val_accuracy: 0.3250\n",
      "Epoch 546/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5470 - accuracy: 0.3950 - val_loss: 1.5997 - val_accuracy: 0.3250\n",
      "Epoch 547/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5427 - accuracy: 0.4202 - val_loss: 1.6007 - val_accuracy: 0.3250\n",
      "Epoch 548/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5068 - accuracy: 0.4034 - val_loss: 1.5997 - val_accuracy: 0.3250\n",
      "Epoch 549/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3930 - accuracy: 0.46 - 0s 12ms/step - loss: 1.4312 - accuracy: 0.4622 - val_loss: 1.6029 - val_accuracy: 0.3250\n",
      "Epoch 550/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6129 - accuracy: 0.3782 - val_loss: 1.6009 - val_accuracy: 0.3250\n",
      "Epoch 551/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5623 - accuracy: 0.4454 - val_loss: 1.6005 - val_accuracy: 0.3250\n",
      "Epoch 552/2500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5969 - accuracy: 0.3782 - val_loss: 1.5990 - val_accuracy: 0.3250\n",
      "Epoch 553/2500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4738 - accuracy: 0.4118 - val_loss: 1.5993 - val_accuracy: 0.3250\n",
      "Epoch 554/2500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.5740 - accuracy: 0.3950 - val_loss: 1.5984 - val_accuracy: 0.3250\n",
      "Epoch 555/2500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5392 - accuracy: 0.3950 - val_loss: 1.5984 - val_accuracy: 0.3250\n",
      "Epoch 556/2500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5339 - accuracy: 0.4286 - val_loss: 1.5991 - val_accuracy: 0.3250\n"
     ]
    }
   ],
   "source": [
    "history = categorical.fit(x_train, y_train, epochs = 2500, batch_size = 64, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'], label = \"train_Accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], label = 'test_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = categorical.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_pred.round(), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training accuracy is very high and testing is low - overfitting\n",
    "#training accuracy is low and testing is high - under fitting\n",
    "#both is similar, then model is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine tuning criteria\n",
    "\n",
    "\n",
    "#change random state value\n",
    "#add hidden layers\n",
    "#add dropout layers\n",
    "#add custom learning rate\n",
    "#changing the batch size and optimizers\n",
    "#adding more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-157-af3a8836a80f>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "yp = categorical.predict_classes(sc.transform([[2, 17, 5, 4.3, 1.3, 8.34]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modeltraining",
   "language": "python",
   "name": "modeltraining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
